[
  {
    "objectID": "dataprep.html",
    "href": "dataprep.html",
    "title": "Data Preparation",
    "section": "",
    "text": "At a Glance",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "dataprep.html#date-data-type",
    "href": "dataprep.html#date-data-type",
    "title": "Data Preparation",
    "section": "Date data type",
    "text": "Date data type\n\nThe date data type in R is used to represent calendar dates, allowing for accurate storage and manipulation of time-related data. Dates in R are typically stored as objects of class Date, which internally represent the number of days since January 1, 1970. This format facilitates arithmetic operations, such as calculating differences between dates or adding/subtracting days. Dates can be created and manipulated using functions like as.Date() for converting character strings to date objects, or Sys.Date() for retrieving the current date. Handling dates correctly is essential in time series analysis, scheduling, and any task involving chronological data, as improper formatting or assumptions can lead to errors in analysis.\n\n\n# Convert date info in format 'mm/dd/yyyy' using as.Date\nstrDates &lt;- c(\"01/05/1965\", \"08/16/1975\")\ndates &lt;- as.Date(strDates, \"%m/%d/%Y\") \nstr(dates)\n\n Date[1:2], format: \"1965-01-05\" \"1975-08-16\"\n\n\n\nThe lubridate package provides additional tools for working with dates, such as parsing and extracting components like year, month, and day. This package makes dates a lot easier to work with.\n\n\n# Convert date info in format 'mm/dd/yyyy' using lubridate\nlibrary(lubridate)\nstrDates &lt;- c(\"01/05/1965\", \"08/16/1975\")\ndates &lt;- mdy(strDates) \nstr(dates)\n\n Date[1:2], format: \"1965-01-05\" \"1975-08-16\"\n\n\n\nIf you are only given a year and a month, you can use the ym() command to turn it to a date. But take note that it will add a day to the value as a placeholder.\n\n\n# Convert date info in format 'yyyymm' using lubridate\nstryyyymm &lt;- c(\"202201\", \"202003\", \"202204\")\ndates &lt;- ym(stryyyymm)\nstr(dates)\n\n Date[1:3], format: \"2022-01-01\" \"2020-03-01\" \"2022-04-01\"\n\n\n\n# Convert date info in format 'mm/dd/yyyy' using as.Date\nstrDates &lt;- c(\"01/05/1965\", \"08/16/1975\")\ndates &lt;- as.Date(strDates, \"%m/%d/%Y\") \nstr(dates)\n\n Date[1:2], format: \"1965-01-05\" \"1975-08-16\"\n\n\n\nUseDates &lt;- read.csv(\"data/Lubridate.csv\")\nUseDates$Date &lt;- ym(UseDates$Date)\n\n#You can use the month or year function to access the month or year from the date\nUseDates$month &lt;- month(UseDates$Date)\nUseDates$year &lt;- year(UseDates$Date)\n\n##Now, you can access months or year numerically\nsummary(UseDates$month) \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   4.000   7.000   6.538   9.000  12.000 \n\nsummary(UseDates$year)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2019    2020    2021    2021    2021    2022 \n\n##You could code the seasons using a mutate function making a new variable \"season\"\nlibrary(tidyverse)\nUseDates &lt;- UseDates %&gt;% \n  mutate(season = case_when(\n    month %in% 3:5 ~ \"Spring\",\n    month %in% 6:8 ~ \"Summer\",\n    month %in% 9:11 ~ \"Fall\",\n    TRUE ~ \"Winter\"\n  ))\n\nUseDates$season &lt;- as.factor(UseDates$season)\nsummary(UseDates$season)\n\n  Fall Spring Summer Winter \n     9      9     12      9 \n\n##You could use a filter statement to select a particular year. \n#In the example below, I save the filtered data into a new data frame UseDate2022. \nUseDate2022 &lt;- filter(UseDates, year==2022)\n\n\nBelow lists some common commands using Lubridate.\n\n\\[\n\\begin{array}{|l|l|}\n\\hline\n\\textbf{Function} & \\textbf{Description} \\\\\n\\hline\n\\texttt{ymd(\"2025-07-08\")} & \\text{Parse a date in Year-Month-Day format} \\\\\n\\texttt{mdy(\"July 8, 2025\")} & \\text{Parse a date in Month-Day-Year format} \\\\\n\\texttt{ym(\"2025-07\")} & \\text{Parse Year-Month (no day)} \\\\\n\\texttt{today()} & \\text{Get the current date} \\\\\n\\texttt{now()} & \\text{Get the current date and time} \\\\\n\\texttt{year(date)} & \\text{Extract the year from a date} \\\\\n\\texttt{month(date)} & \\text{Extract the month (number)} \\\\\n\\texttt{month(date, label=TRUE)} & \\text{Extract the month (name)} \\\\\n\\texttt{day(date)} & \\text{Extract the day of the month} \\\\\n\\texttt{wday(date)} & \\text{Get weekday (number)} \\\\\n\\texttt{wday(date, label=TRUE)} & \\text{Get weekday (name)} \\\\\n\\hline\n\\end{array}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "dataprep.html#full-examples",
    "href": "dataprep.html#full-examples",
    "title": "Data Preparation",
    "section": "Full Examples",
    "text": "Full Examples\n\ngss.2016 Data Cleaning\n\nFirst, because we made some edits to the data set, reread in version a using the read.csv command. This brings the data set back to its original form. It is always a good idea to read the dataset back in when you are unsure about whether you have made a mistake during data preparation that could cause a lack of data integrity.\n\n\n\ngss.2016 &lt;- read.csv(file = \"data/gss2016.csv\") \n\n\nBefore we remove any missing data, we need it to be the correct data type. In this case, grass should be a factor.\n\n\n# We coerced this variable earlier, but the object was called gss.2016. \n#Since we reread in the data set, this needs to be done again. \ngss.2016$grass &lt;- as.factor(gss.2016$grass)\n\n\nThe statement below is an equivalent to the function above, but written with the piping operator. It is overwriting gss.2016 after conducting the coercion to factor.\nWe added the mutate function because we are going to add other data cleaning tasks to this statement.\n\n\ngss.2016 &lt;- gss.2016 %&gt;% mutate(grass = as.factor(grass))\n\n\nPiping to More Functions: Missing Data\n\nIn the code below, the as.factor() command has been moved inside a broader mutate statement (that uses tidyverse library) and piped to it the na_if() command that handles missing data. If you use more than one data manipulation statement, the mutate() command is needed to help organize your code with one mutate() is needed for each major change you are making.\nIn the code below, we created a new object gss.2016.cleaned to help store the cleaned version of the dataset. This helps maintain data integrity because your original dataset is still intact and each time, you rerun the entire chunk, which includes all the changes at one time.\n\n\ngss.2016.cleaned &lt;- gss.2016 %&gt;%\n  #Moved coercion statement into a mutate function to keep code tidy\n  mutate(grass = as.factor(grass)) %&gt;% \n  #Moving DK value to NA for not applicable\n  mutate(grass = na_if(x = grass, y = \"DK\"))\n\n#Check the summary, there should be 110 + 3 = 113 in the NA category \nsummary(object = gss.2016.cleaned)\n\n       grass          age           \n DK       :   0   Length:2867       \n IAP      : 911   Class :character  \n LEGAL    :1126   Mode  :character  \n NOT LEGAL: 717                     \n NA's     : 113                     \n\n\n\n\nDrop Levels\n\nThe droplevels function is part of base R and is used to drop unused levels from factor variables in a data frame. It works by removing any levels from a factor variable that are not present in the data.\nNext, we want to edit our code to convert IAP and DK to NA values and drop levels that have are empty.\n\nNote the Piping operator added to the end of the DK line so you can keep going with new commands editing gss.2016.cleaned.\n\n\ngss.2016.cleaned &lt;- gss.2016 %&gt;% \n  mutate(grass = as.factor(grass)) %&gt;% \n  #Added piping operator\n  mutate(grass = na_if(x = grass, y = \"DK\")) %&gt;%   \n  #Turn to na if value of grass = IAP\n  mutate(grass = na_if(x = grass, y = \"IAP\")) %&gt;% \n  #Drop levels in grass that have no values\n  mutate(grass = droplevels(x = grass))  \n#Check what you just did\nsummary(gss.2016.cleaned) \n\n       grass          age           \n LEGAL    :1126   Length:2867       \n NOT LEGAL: 717   Class :character  \n NA's     :1024   Mode  :character  \n\n\n\n\n\nCoercing to Numeric\n\nNext, we handle a numerical variable, age. Age again has an issue being able to be numerical data type because it has “89 OR OLDER” as a value. Before using the as.numeric() command, we need to recode it. We did this above as a stand-alone statement.\n\n\n\ngss.2016.cleaned &lt;- gss.2016 %&gt;% \n  mutate(grass = as.factor(grass)) %&gt;% \n  mutate(grass = na_if(x = grass, y = \"DK\")) %&gt;% \n  mutate(grass = na_if(x = grass, y = \"IAP\")) %&gt;% \n  #Added piping operator \n  mutate(grass = droplevels(x = grass)) %&gt;% \n  #Ensure variable can be coded as numeric and fix if necessary. \n  mutate(age = recode(age, \"89 OR OLDER\" = \"89\")) %&gt;% \n  #Coerce into numeric\n  mutate(age = as.numeric(x = age)) \n\n#Check what you just did\nsummary(gss.2016.cleaned) \n\n       grass           age       \n LEGAL    :1126   Min.   :18.00  \n NOT LEGAL: 717   1st Qu.:34.00  \n NA's     :1024   Median :49.00  \n                  Mean   :49.16  \n                  3rd Qu.:62.00  \n                  Max.   :89.00  \n                  NA's   :10     \n\n\n\nThe recode() command that is part of dplyr is like the ifelse() command that is in base R. There are a lot of ways to recode in R.\nFinally, we want to take our numerical variable, age, and cut it at certain breaks to make categories that can be easily analyzed.\n\nThis also ensures that anyone above 89 is coded correctly in a category instead of as the value 89. This again brings back data integrity.\nLast, we want to recode the age variable into categories. We can use the case_when to do this.\n\n\n\ngss.2016.cleaned &lt;- gss.2016 %&gt;% \n     mutate(grass = as.factor(grass)) %&gt;% \n     mutate(grass = na_if(x = grass, y = \"DK\")) %&gt;% \n     mutate(grass = na_if(x = grass, y = \"IAP\")) %&gt;% \n     mutate(grass = droplevels(x = grass)) %&gt;% \n     mutate(age = recode(age, \"89 OR OLDER\" = \"89\")) %&gt;% \n     #Added piping operator\n     mutate(age = as.numeric(x = age)) %&gt;% \n     #Cut numeric variable into groupings\n     mutate(age.cat = as.factor(case_when(\n          age &lt; 30 ~ \"&lt; 30\",\n          age &gt;= 30 & age &lt;= 59 ~ \"30 - 59\",\n          age &gt;= 60 & age &lt;= 74 ~ \"60 - 74\",\n          age &gt;= 75 ~ \"75+\",\n          TRUE ~ NA_character_  # Safety net for NAs\n     )))\n#Check what you just did\nsummary(gss.2016.cleaned) \n\n       grass           age           age.cat    \n LEGAL    :1126   Min.   :18.00   &lt; 30   : 481  \n NOT LEGAL: 717   1st Qu.:34.00   30 - 59:1517  \n NA's     :1024   Median :49.00   60 - 74: 598  \n                  Mean   :49.16   75+    : 261  \n                  3rd Qu.:62.00   NA's   :  10  \n                  Max.   :89.00                 \n                  NA's   :10                    \n\n\n\n\n\nbrfss Data Cleaning\n\nThe full codebook where this screenshot is taken is brfss_2014_codebook.pdf.\n\n\n\n\nEvaluate CodeBook Before Making Decisions\n\n\n\nbrfss &lt;- read.csv(\"data/brfss.csv\")\nsummary(brfss)\n\n    TRNSGNDR        X_AGEG5YR          X_RACE         X_INCOMG    \n Min.   :1.000    Min.   : 1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:4.000    1st Qu.: 5.000   1st Qu.:1.000   1st Qu.:3.000  \n Median :4.000    Median : 8.000   Median :1.000   Median :5.000  \n Mean   :4.059    Mean   : 7.822   Mean   :1.992   Mean   :4.481  \n 3rd Qu.:4.000    3rd Qu.:10.000   3rd Qu.:1.000   3rd Qu.:5.000  \n Max.   :9.000    Max.   :14.000   Max.   :9.000   Max.   :9.000  \n NA's   :310602                    NA's   :94                     \n    X_EDUCAG        HLTHPLN1         HADMAM          X_AGE80     \n Min.   :1.000   Min.   :1.000   Min.   :1.000    Min.   :18.00  \n 1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000    1st Qu.:44.00  \n Median :3.000   Median :1.000   Median :1.000    Median :58.00  \n Mean   :2.966   Mean   :1.108   Mean   :1.215    Mean   :55.49  \n 3rd Qu.:4.000   3rd Qu.:1.000   3rd Qu.:1.000    3rd Qu.:69.00  \n Max.   :9.000   Max.   :9.000   Max.   :9.000    Max.   :80.00  \n                                 NA's   :208322                  \n    PHYSHLTH   \n Min.   : 1.0  \n 1st Qu.:20.0  \n Median :88.0  \n Mean   :61.2  \n 3rd Qu.:88.0  \n Max.   :99.0  \n NA's   :4     \n\n\n\nQualitative Variable\n\nTo look at an example, the one below seeks to understand the healthcare issue in reporting gender based on different definitions. The dataset is part of the Behavioral Risk Factor Surveillance System (brfss) dataset (2014), which includes lots of other variables besides reported gender.\n\n\n#Load the data\nbrfss &lt;- read.csv(\"data/brfss.csv\")\n#Summarize the TRNSGNDR variable\nsummary(object = brfss$TRNSGNDR) \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  1.000   4.000   4.000   4.059   4.000   9.000  310602 \n\n#Find frequencies \ntable(brfss$TRNSGNDR) \n\n\n     1      2      3      4      7      9 \n   363    212    116 150765   1138   1468 \n\n\n\nSince this table is not very informative, we need to do some edits.\nCheck the class of the variable to see the issue with analyzing it as a categorical variable.\n\n\nclass(brfss$TRNSGNDR)\n\n[1] \"integer\"\n\n\n\nFirst, we need to change the TRNSGNDR variable to a factor using as.factor().\n\n\n# Change variable from numeric to factor\nbrfss$TRNSGNDR &lt;- as.factor(brfss$TRNSGNDR)\n# Check data type again to ensure factor\nclass(brfss$TRNSGNDR)\n\n[1] \"factor\"\n\n\n\nThen, we need to do some data cleaning on the TRNSGNDR Variable.\n\n\nbrfss.cleaned &lt;- brfss %&gt;% \n  mutate(TRNSGNDR = recode_factor(TRNSGNDR,\n      '1' = 'Male to female',\n      '2' = 'Female to male',\n      '3' = 'Gender non-conforming',\n      '4' = 'Not transgender',\n      '7' = 'Not sure',\n      '9' = 'Refused'))\n\n\nWe can use the levels() command to show the factor levels made with the mutate() command above.\n\n\nlevels(brfss.cleaned$TRNSGNDR)\n\n[1] \"Male to female\"        \"Female to male\"        \"Gender non-conforming\"\n[4] \"Not transgender\"       \"Not sure\"              \"Refused\"              \n\n\n\nCheck the summary.\n\n\nsummary(brfss.cleaned$TRNSGNDR)\n\n       Male to female        Female to male Gender non-conforming \n                  363                   212                   116 \n      Not transgender              Not sure               Refused \n               150765                  1138                  1468 \n                 NA's \n               310602 \n\n\n\nTake a good look at the table to interpret the frequencies in the output above. The highest percentage was the “NA’s” category, followed by “Not transgender”. Removing the NA’s moved the “Not transgender” category to over 97% of observations.\n\n\n\nQuantitative Variable\n\nLet’s use the cleaned dataset to make more changes to the continuous variable PHYSHLTH. In the codebook, it looks like the data is most applicable to the first 2 categories. The 1-30 days coding and the 88 coding, which means 0 days of physical illness and injury.\n\nUsing cleaned data, we need to prep the variable a little more before getting an accurate plot.\nSpecifically, we need to null out the 77 and 99 values and make sure the 88 coding is set to be 0 for 0 days of illness and injury.\n\n\n\nbrfss.cleaned &lt;- brfss %&gt;% \n  mutate(TRNSGNDR = recode_factor(TRNSGNDR,\n      '1' = 'Male to female',\n      '2' = 'Female to male',\n      '3' = 'Gender non-conforming',\n      '4' = 'Not transgender',\n      '7' = 'Not sure',\n      '9' = 'Refused')) %&gt;%\n  #Turn the 77 values to NA's. \n  mutate(PHYSHLTH = na_if(PHYSHLTH, y = 77)) %&gt;%\n  #Turn the 99 values to NA's. \n  mutate(PHYSHLTH = na_if(PHYSHLTH, y = 99)) %&gt;%\n  #Recode the 88 values to be numeric value of 0. \n  mutate(PHYSHLTH = recode(PHYSHLTH, '88' = 0L))\n\n\nThe histogram showed most people have between 0 and 10 unhealthy days per 30 days.\nNext, evaluate mean, median, and mode for the PHYSHLTH variable after ignoring the blanks.\n\n\nmean(brfss.cleaned$PHYSHLTH, na.rm=TRUE)\n\n[1] 4.224106\n\nmedian(brfss.cleaned$PHYSHLTH, na.rm=TRUE)\n\n[1] 0\n\nnames(x = sort(x = table(brfss.cleaned$PHYSHLTH), decreasing = TRUE))[1]\n\n[1] \"0\"\n\n\n\nWhile the mean is higher at 4.22, the median and most common number is 0.\n\n\n## Spread to Report with the Mean\nvar(brfss.cleaned$PHYSHLTH, na.rm=TRUE)\n\n[1] 77.00419\n\nsd(brfss.cleaned$PHYSHLTH, na.rm=TRUE)\n\n[1] 8.775203\n\n##Spread to Report with Median\nsummary(brfss.cleaned$PHYSHLTH, na.rm=TRUE)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  0.000   0.000   0.000   4.224   3.000  30.000   10303 \n\nrange(brfss.cleaned$PHYSHLTH, na.rm=TRUE)\n\n[1]  0 30\n\nmax(brfss.cleaned$PHYSHLTH, na.rm=TRUE)-min(brfss.cleaned$PHYSHLTH, na.rm=TRUE)\n\n[1] 30\n\nIQR(brfss.cleaned$PHYSHLTH, na.rm=TRUE)\n\n[1] 3\n\n\n\nlibrary(semTools)\n# Plot the data\nbrfss.cleaned %&gt;% \n  ggplot(aes(PHYSHLTH)) + geom_histogram()\n\n\n\n\n\n\n\n# Calculate Skewness and Kurtosis\nskew(brfss.cleaned$PHYSHLTH)\n\nskew (g1)        se         z         p \n    2.209     0.004   607.905     0.000 \n\nkurtosis(brfss.cleaned$PHYSHLTH)\n\nExcess Kur (g2)              se               z               p \n          3.474           0.007         478.063           0.000 \n\n\n\nThe skew results provide a z of 607.905 (6.079054e+02) which is much higher than 7 (for large datasets). This indicates a clear right skew which means the data is not normally distributed.\nThe kurtosis results are also very leptokurtic with a score of 478.063.\n\n\n\nUsing Filters Example\n\nBelow takes an example of the brfss data to filter by certain variable statuses.\n\nThe first filter() chose observations that were any one of the three categories of transgender included in the data. Used the | “or” operator for this filter().\nThe second filter chose people in an age category above category 4 but below category 12, in the age categories 5 through 11.\nThe last filter used the !is.na to choose observations where HADMAM variable was not NA.\n\nNext, we reduce data set to contain only variables used to create table by using the select() command.\nNext, we change all the remaining variables in data set to factors using mutate_all() command. This not only changes the strings to factors, but also changes the numerical variables to factors.\nFinally, we use mutate() commands to change the variable category to something meaningful(from the codebook).\n\nNotice the backslash before the apostrophe in Don’t in the X_INCOMG recode. This is to prevent the .R file from ending the quotations. You could use double quotes around the statement to bypass this, or add the backslash like I did here.\n\n\nbrfss_small &lt;- brfss.cleaned %&gt;%\n  filter(TRNSGNDR == 'Male to female'|\n        TRNSGNDR ==  'Female to male'|\n        TRNSGNDR ==  'Gender non-conforming') %&gt;%\n  filter(X_AGEG5YR &gt; 4 & X_AGEG5YR &lt; 12) %&gt;% \n  filter(!is.na(HADMAM)) %&gt;%\n  select(TRNSGNDR, X_AGEG5YR, X_RACE, X_INCOMG, X_EDUCAG, HLTHPLN1, HADMAM) %&gt;%\n  mutate_all(as.factor) %&gt;%\n  #The next few mutates add labels to categorical variables based on the codebook. \n  mutate(X_AGEG5YR = recode_factor(X_AGEG5YR,\n          '5' = '40-44',\n          '6' = '45-49',\n          '7' = '50-54',\n          '8' = '55-59',\n          '9' = '60-64',\n          '10' = '65-69',\n          '11' = '70-74')) %&gt;%\n  mutate(X_INCOMG = recode_factor(X_INCOMG,\n          '1' = 'Less than 15,000',\n          '2' = '15,000 to less than 25,000',\n          '3' = '25,000 to less than 35,000',\n          '4' = '35,000 to less than 50,000',\n          '5' = '50,000 or more',\n          '9' = 'Don\\'t know/not sure/missing')) %&gt;%\n     mutate(X_EDUCAG = recode_factor(X_EDUCAG,\n          '1' = 'Did not graduate high school',\n          '2' = 'Graduated high school',\n          '3' = 'Attended college/technical school',\n          '4' = 'Graduated from college/technical school',\n          '9' = NA_character_)) %&gt;%\n     mutate(HLTHPLN1 = recode_factor(HLTHPLN1,\n          '1' = 'Yes',\n          '2' = 'No',\n          '7' = 'Don\\'t know/not sure/missing',\n          '9' = 'Refused')) %&gt;%\n     mutate(X_RACE = recode_factor(X_RACE,\n          '1' = 'White',\n          '2' = 'Black',\n          '3' = 'Native American',\n          '4' = 'Asian/Pacific Islander',\n          '5' = 'Other',\n          '6' = 'Other',\n          '7' = 'Other',\n          '8' = 'Other',\n          '9' = 'Other'))\n#print a summary\nsummary(brfss_small)     \n\n                  TRNSGNDR   X_AGEG5YR                     X_RACE   \n Male to female       : 77   40-44:27   White                 :152  \n Female to male       :113   45-49:27   Black                 : 31  \n Gender non-conforming: 32   50-54:32   Native American       :  4  \n Not transgender      :  0   55-59:44   Asian/Pacific Islander:  6  \n Not sure             :  0   60-64:44   Other                 : 29  \n Refused              :  0   65-69:24                               \n                             70-74:24                               \n                        X_INCOMG                                     X_EDUCAG \n Less than 15,000           :46   Did not graduate high school           :24  \n 15,000 to less than 25,000 :44   Graduated high school                  :86  \n 25,000 to less than 35,000 :19   Attended college/technical school      :68  \n 35,000 to less than 50,000 :26   Graduated from college/technical school:44  \n 50,000 or more             :65                                               \n Don't know/not sure/missing:22                                               \n\n HLTHPLN1  HADMAM \n Yes:198   1:198  \n No : 24   2: 22  \n           9:  2  \n\n\n\n\n\n\nThis data set full of categorical variables is now fully cleaned and ready to be analyzed!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "dataprep.html#layering-in-ggplot",
    "href": "dataprep.html#layering-in-ggplot",
    "title": "Data Preparation",
    "section": "Layering in ggplot",
    "text": "Layering in ggplot\n\nLayering is a fundamental concept in ggplot2 that allows you to build complex visualizations by adding different components (or “layers”) on top of each other. Each layer in a ggplot2 plot can represent different types of data, aesthetics, or annotations, enabling flexibility and control over how data is visualized. Layers can include geometries (e.g., points, lines, bars), statistical summaries, labels, grids, and themes.\nSeparation of Plot Components: Each layer can handle a different part of the plot. For example, one layer may be used for bars, another for labels, and another for a trend line. This allows you to build up a plot step by step.\nCustomization and Enhancement: By adding multiple layers, you can customize different aspects of the plot such as labels, colors, annotations, and theme elements. Each layer can be independently controlled.\nModularity: Layering allows you to modularize your plot construction, making it easier to add, remove, or modify parts of the plot without changing the entire structure.\nCombining Data Sources: Different layers can use different datasets or aesthetics, which is useful when you need to overlay one dataset on top of another (e.g., adding a regression line over a scatter plot).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "dataprep.html#graphs-for-a-single-categorical-variable",
    "href": "dataprep.html#graphs-for-a-single-categorical-variable",
    "title": "Data Preparation",
    "section": "Graphs for a Single Categorical Variable",
    "text": "Graphs for a Single Categorical Variable\n\nA categorical variable has categories that are either ordinal with a logical order or nominal with no logical order.\nCategorical variables need to be set as the factor data type in R to be able to be analyzed and visualized correctly.\nSome common graphing options for single categorical variable:\n\nBar graph\nPie chart\n\nIn any graph, it is beneficial to do any data cleaning and investigation into the variable(s) before you begin. With categorical variables, this may require recoding the factor(s) of interest and possibly renaming it/them to something meaningful if needed.\n\n\nBar Graph\n\nA bar graph depicts the frequency or the relative frequency for each category of the qualitative data as a bar rising vertically from the horizontal axis. A bar graph is also known as a bar chart and is often used to examine similarities and differences across categories of things; bars can represent frequencies, percentages, means, or other statistics.\nWe can learn a lot from a bar graph, like the marital status group with the highest and lowest frequencies according to the census.gov.\n\n\n\n\n\n\n\n\n\n\n\ngeom_bar()\n\nCreate a Bar Graph using ggplot() Command\nLike histograms, ggplot has many more parameters available over base R to construct bar graphs.\nFirst, we load tidyerse to access ggplot() command and others. You can always do this at the start of all your code to keep all the libraries together that are being used.\n\n\nlibrary(\"tidyverse\")\n\n\nggplot() works in layers, so you will routinely see the + symbol to kick off a new layer with added functionality.\nUsing the ggplot, we always include the aes() command first inside the ggplot() command. The aes() command is a quoting function that describes the variables being used. From there, it depends on the plot.\n\nFirst layer: ggplot() and aes() which calls the dataset and variables used.\nSecond layer: Graph type: Bar graph: geom_bar().\nAdditional layers: labs - for labels including titles; themes; and geom_text. Recreate the example below adding one layer at a time to see how the visualization changes.\n\n\n\n\nPertinent Parameters to the geom_bar()\n\nstat=“identity”: In ggplot2, the argument stat=“identity” is used inside the geom_bar when creating bar charts to specify that the actual values of the data should be plotted, rather than calculated summary statistics. By default, ggplot assumes that bar charts use stat=“count”, which counts the number of observations in each category. When you want to display the actual values in your dataset (e.g., sales numbers, average scores), you need to set stat=“identity” to ensure that the y-values are mapped directly from the data rather than being automatically counted.\nposition=“dodge”: If we have more than one categorical variable, we might set the position=“dodge” argument. This argument controls how the bars are positioned relative to each other when you are plotting multiple categories within a bar chart. By default, bars in a bar chart are stacked, and setting position=“dodge” ensures that they are placed side-by-side. This is particularly useful when you are comparing multiple groups or categories within the same plot, as it allows for a clear visual distinction between each group. In the example below, we only have one variable, so position=“dodge” argument is not needed.\n\nIn combination, using stat=“identity” and position=“dodge” is common when you want to compare different categories or groups with specific values in a side-by-side manner, ensuring the chart is easy to interpret. For example, if you are comparing sales figures across different products for multiple years, this approach would give you a bar for each product in each year, clearly separated.\nshow.legend = FALSE: In ggplot2, the argument show.legend = FALSE is used to hide the legend for a particular layer or the entire plot. By default, ggplot2 automatically adds a legend if you include aesthetics like color, size, or shape that distinguish groups in your data. If you don’t want the legend to appear, you can set show.legend = FALSE.\nscale_fill_manual(): When creating grouped bar charts or other plots with multiple categories, it’s important to ensure that the visual distinction between groups is clear. This is where manually setting the colors for each category comes into play. The scale_fill_manual() function in ggplot2 allows you to manually define the colors used for the filled areas, such as the bars in a bar chart or the shaded areas in an area chart. By using the values argument within scale_fill_manual(), you can specify a custom color palette that suits your design or presentation needs. For example, you might choose a palette of yellow and brown to represent different categories. A key aspect of using scale_fill_manual() effectively is knowing how many colors to provide. The number of colors you define in the values argument must match the number of levels or categories in your data. If you are comparing three product categories, for instance, you’ll need to provide exactly three colors—one for each category. Failing to match the number of colors to the number of categories can result in errors or misrepresentation in the plot. For example, if you have four levels (e.g., four different product categories or groups) and only provide two colors, ggplot may not know how to properly assign colors to the additional categories. Therefore, it’s crucial to know the number of distinct categories in your data and plan your color palette accordingly to maintain clarity and visual consistency in your chart.\n\n\n##inputting probabilities calculated from a 2023 multiple choice question. \n# From what you learned about R so far, how do you expect its market share to change?\nGoUp &lt;- .54285\nGoDown &lt;- .03809\nRemainStable &lt;- .34285\nNoOpinion &lt;- .07619\n#designing the data frame\ndata_frame &lt;- data.frame(\n     Category = c(\"Go Up\", \"Go Down\", \"Remain Stable\", \"No Opinion\"),\n     Percentage = c(GoUp, GoDown, RemainStable, NoOpinion)\n)\n#Making the graph\nMarketShare &lt;- ggplot(data_frame, aes(x = Category, y = Percentage, fill = Category)) +\n     geom_bar(stat = \"identity\", show.legend = FALSE) +\n     labs(title = \"How do you expect R's market share to change?\",\n          x = \"Opinion Category\",\n          y = \"Percentage (%)\") +\n     theme_minimal()+\n     geom_text(aes(label = Percentage), vjust = -0.5, size = 4) + \n     scale_fill_manual(values=c(\"red\", \"blue\", \"purple\", \"green\"))\n\nMarketShare\n\n\n\n\n\n\n\n\n\n\n\nBar Graph with Data Wrangling\n\nLet’s start an example from scratch so that we can see each parameter take effect. In doing so, lets use a dataset to make a bar graph instead of relying on pre-calculated data.\n\nLets examine the AUQ300 variable from the nhanes survey to run an example.\n\n\nnhanes &lt;- read.csv(\"data/nhanes2012.csv\")\n\n\nNext, we need to check the import by looking at the summary or head of the data.\n\n\n#Results hidden to save space, but gives you the first 6 records in the data set. \nhead(nhanes)\n\n\nWe can also check the summary of data of only the variable of interest, AUQ300, to get a sense of what we are evaluating.\n\n\nsummary(nhanes$AUQ300) \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  1.000   1.000   2.000   1.656   2.000   7.000    4689 \n\n\n\nThe AUQ300 variable represents gun use. A screenshot of the codebook is copied below so that we can see what AUQ300 really refers to. It is available on https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/AUQ_G.htm. This is always a necessary step because variable names can be convoluted and not representative of the variable definition.\n\n\n\n\nAUQ300\n\n\n\nRecode Variable if Needed\n\nLook to see if the AUQ300 needs recoding after looking at the codebook and making sense of the variable.\nAUQ300 needs to be a factor variable with 1 equaling a Yes and 2 equaling a No. We can use recode_factor to accomplish 2 things at once with the mutate function.\nrecode_factor() transforms the levels of a categorical variable (factor) into a new set of levels and is specific to categorical variables.\nrecode() is generic and can apply to numerical, categorical, or textual data, but still transforms data from one format or code to another.\n\n\nnhanes.clean &lt;- nhanes %&gt;%\n  select(AUQ300) %&gt;%\n  mutate(AUQ300 = recode_factor(AUQ300,\n    '1' = 'Yes',\n    '2' = 'No'))\n\n\nThen, we need to check the recode for accuracy. You should see the No’s and Yes’s alongside the rest being coded as NA’s.\n\n\nsummary(nhanes.clean)\n\n  AUQ300    \n Yes :1613  \n No  :3061  \n NA's:4690  \n\n\n\n\nGet Bar Roughly Plotted\n\nStart with the basic plot using the ggplot() and geom_bar() commands.\nBelow writes the statement with and without the piping operator.\n\nSince we are also going to use data preparation techniques, the piping operator is recommended.\n\n\n# Without piping operator\nggplot(nhanes.clean, aes(x = AUQ300)) + geom_bar()\n\n\n\n\n\n\n\n#With piping operator\nnhanes.clean %&gt;%\n  ggplot(aes(x = AUQ300)) + geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nAdd Functions to Clean Chart\n\nOmit the NA category from AUQ300 variable, which represents gun use. Then plot the graph below.\nThe drop_na() function is a good way to drop NA values from either the entire dataset or just one variable. It was introduced in the data prep lesson. Since we are only interested in dropping NA values from our one variable of interest that is to be graphed (AUQ300), we can put it in the parentheses so that we do not unintentionally drop lots of observations for no reason.\nAdd an axis labels under labs(x = …, y=…).\n\n\nnhanes.clean %&gt;%\n  drop_na(AUQ300) %&gt;%\n  ggplot(aes(x = AUQ300)) + geom_bar() +\n  labs(x = \"Gun use\", y = \"Number of participants\")\n\n\n\n\n\n\n\n##Here, we really benefit from the piping operator because we are doing more than one thing.\n\n\nFrom the bar graph, we can see that almost double the amount of people have not fired a firearm for any reason than those that fired one.\n\n\n\nAdding Color\n\nThere are many ways to add color to a bar graph. Below, the color is filled in directly in the aes() command by choosing it to give a different color to each categorical value of AUQ300.\n\nWhen fill is mapped to a variable, the fill color of the geom will vary based on the values of that variable. This is useful for distinguishing different groups or categories within the data. In this case the fill=AUQ300 gives a distinct color pattern based on how many categories there are considering the fact we are using the default “scale.”\n\n\nnhanes.clean %&gt;%\n  drop_na(AUQ300) %&gt;%\n  ggplot(aes(AUQ300, fill=AUQ300)) +\n  geom_bar() +\n  labs(x = \"Gun use\", y = \"Number of participants\", \n       subtitle = \"Filled inside the aes()\") \n\n\n\n\n\n\n\n\n\n\n\nData Prep and Then Visualized\n\nIn the command below, we create a gss.2016.cleaned object to make a barplot. In doing so, we do the following:\nCreate a bar graph using the ggplot() command, which requires an aes() quoting function. This function says that we want to use the grass variable in our bar graph.\nDrop all NAs from the grass variable so that legal and not legal are the only categories.\nWe then create the bars and fill them with 2 colors, red and purple. Many color codes can be used here, and will be discussed in a later lesson.\nWe then add labels to our graph on both x and y axis.\nFinally, we print the new graph, which is saved under the legalize.bar object.\nBelow, I brought back over the code from the last part in Data Preparation. You should still have this in your Chapter1.R file. We are going to use that file to create a graphics in R.\n\n\ngss.2016 &lt;- read_csv(file = \"data/gss2016.csv\") \ngss.2016.cleaned &lt;- gss.2016 %&gt;% \n  mutate(grass = as.factor(grass)) %&gt;% \n  mutate(grass = na_if(x = grass, y = \"DK\")) %&gt;% \n  mutate(grass = na_if(x = grass, y = \"IAP\")) %&gt;% \n  mutate(grass = droplevels(x = grass)) %&gt;% \n  mutate(age = recode(age, \"89 OR OLDER\" = \"89\")) %&gt;% \n  mutate(age = as.numeric(x = age)) %&gt;% \n  mutate(age.cat = cut(x = age, breaks = c(-Inf, 29, 59, 74, Inf),labels = c(\"&lt; 30\", \"30 - 59\", \"60 - 74\", \"75+\" ))) \n\n\nOnce the data is prepped, we can graph the variable or variables.\n\n\nggplot(gss.2016.cleaned, aes(grass)) + geom_bar() ##with no piping operator\n\n\n\n\n\n\n\ngss.2016.cleaned %&gt;% ggplot(aes(grass)) + geom_bar() ##with piping operator\n\n\n\n\n\n\n\n\n\n# Make a Bar Graph for Grass Variable\ngss.2016.cleaned %&gt;% \n     drop_na() %&gt;%\n     ggplot(aes(grass)) + geom_bar(fill=c(\"red\", \"blue\")) + \n     labs(x = \"Should marijuana be legal\", y=\"Frequency of Responses\")\n\n\n\n\n\n\n\n\n\n\nEdit The Graphic\n\nNext, we can edit these commands to include the age variable. The aes() quoting function has expanded to have the bars filled color using the grass variable, the age category has replaced the grass variable on the x axis.\n\n\ngss.2016.cleaned %&gt;% \n     drop_na() %&gt;%\n     ggplot(aes(age.cat, fill=grass)) + geom_bar() + labs(x=\"Age Category\", y=\"Frequency of responses\")\n\n\n\n\n\n\n\n\n\nWe can add the position set at “dodge” inside the geom_bar() layer to make the barchart unstacked (or grouped).\n\n\ngss.2016.cleaned %&gt;% \n     drop_na() %&gt;%\n     ggplot(aes(age.cat, fill=grass)) + geom_bar(position=\"dodge\") + labs(x=\"Age Category\", y=\"Frequency of responses\")\n\n\n\n\n\n\n\n\n\nWe can edit further to include a new a formula on the y axis to sum and count.\nIn the formula you provided, after_stat(count) is used within the ggplot2 framework to refer to the computed statistic generated by the geom_bar() function. Specifically, in the context of bar plots, count refers to the number of observations (or frequency) for each category within the data.\nWhen you use after_stat(count), you are referencing the count that is computed after geom_bar() has processed the data and calculated how many observations fall into each group (in this case, within each age category and the “grass” variable, which likely refers to attitudes toward marijuana legalization).\nWe also gave this a theme and updated the labels.\n\n\ngss.2016.cleaned %&gt;% \n     drop_na() %&gt;%\n     ggplot(aes(age.cat, y = 100*(after_stat(count))/sum(after_stat(count)), \n                fill=grass)) + \n     geom_bar(position = 'dodge')+  \n     theme_minimal()+ \n     labs(x = \"Age Category\",y = \"Percent of responses\")\n\n\n\n\n\n\n\n\n\nEvaluate these graphs and see what information you can get from them.\n\n\n\n\nPie vs Bar Charts\n\nRecommended graphs for single categorical or factor type variable:\n\nBar graph, for showing relative group sizes.\nPie charts are available in R but are not recommended because they tend to be less clear for comparing group sizes.\n\nPie charts are difficult to read since the relative size of pie pieces is often hard to determine.\nPie charts take up a lot of space to convey little information.\nPeople often use fancy formatting like 3D, which takes up more space and makes understanding relative size of pie pieces even more difficult.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "dataprep.html#graphs-for-a-single-continuous-variable",
    "href": "dataprep.html#graphs-for-a-single-continuous-variable",
    "title": "Data Preparation",
    "section": "Graphs for a Single Continuous Variable",
    "text": "Graphs for a Single Continuous Variable\n\nA continuous variable refers to a variable that can take any value over a range of values.\nA continuous variable needs to be numeric, and could be integer type or numeric type in R. Just like with graphs that include categorical variables, it is beneficial to do any data cleaning and investigation into the variable(s) before you begin. With continuous variables, this may require recoding the variable to coerce it to the appropriate data type and/or renaming it to something meaningful if needed.\nIt is also beneficial to make sure the numerical variable is indeed supposed to be numerical (as opposed to a factor). For instance, you commonly see numbers listed for categories like the Yes/No coded as a 1/2, such as with the AUQ300 variable.\n\nSome common graphing options for single continuous variable:\n\nHistograms\nDensity plots\nBoxplots\nViolin plots\n\n\nHistograms\n\nA histogram is a useful plot to determine central tendency and spread.\nWe went over histograms in Lesson 2, so refer back for information on how to create a histogram using base R and ggplot.\nRemember that you can tell the distribution from a histogram, and that distribution can be normal or skewed (Right or Left).\n\nWith each chart based on quantitative data, you should be able to get a sense of the distribution.\nThe histogram below looks right skewed.\n\n\n\n\n\n\n\n\n\n\n\n\nDensity Plots\n\nA density plot is similar to a histogram but more fluid in appearance because it does not have the separate bins.\n\nProbability density is not very useful for interpreting what is happening at any given value of the variable on the x-axis, but it is useful in computing the percentage of values that are within a range along the x-axis.\nThe area under the curve in a density plot could be interpreted as the probability of a single observation or a range of observations.\nWe can use random normal data to create the density plot like shown below with a sample of 1000, a mean of 10 and a standard deviation of 2. To do this, we need to make the vector and assign it to a data frame.\nIn R, set.seed() is a function used to set the seed for random number generation. By setting a seed using set.seed(), you ensure reproducibility of your code. If you run the same code with the same seed, you’ll get the same sequence of random numbers every time. This is particularly useful for debugging, testing, or when you want to ensure that your results are reproducible.\nWe use set.seed before any function with a random normal generator to ensure reproducibility.\nIf a dataset is provided, then you do not need to generate your own random data as shown in the step below.\n\n\n\nset.seed(1)\nx &lt;- rnorm(1000, mean = 10, sd=2)\ndf &lt;- data.frame(x)\n\n\nNext, we can make the density plot using the ggplot2 package under tidyverse.\n\nLayer 2 includes the geom_density() command in addition to the standard Layer 1 ggplot() command to create the density plot.\n\n\n\nggplot(df, aes(x)) + geom_density()\n\n\n\n\n\n\n\n\n\nThere are a lot of arguments you can change. I selected a couple below. Be sure to look at the help file on the geom_density() layer to get the variety on what you can do.\n\ncolor = sets a line color\nlwd = makes the line thicker. Increase this number for thicker line.\nfill= colors the area under the curve.\nalpha= sets the transparency to the area under the curve.\n\n\n\nggplot(df, aes(x)) + geom_density(color = \"darkblue\", lwd = 2)\n\n\n\n\n\n\n\n\n\nggplot(df, aes(x)) + geom_density(color = \"darkblue\", fill = \"lightblue\",alpha = .5) \n\n\n\n\n\n\n\n\n\nWe can even add a mean line, which we know in this case is 10 because we used random normal data with that mean set as a parameter.\ngeom_vline() is a function used to add vertical lines to a plot created with ggplot. This function is useful for visually indicating specific points or ranges on the x-axis.\nYou can do a line break in your R code after a comma (\\(,\\)) or after a plus sign (\\(+\\)). I find things easier to read on less lines, but it is personal preference how many lines you use given still following the rules in R.\n\n\n\nggplot(df, aes(x)) +\n  geom_density(color = \"darkblue\", fill=\"lightblue\", alpha=.5) + \n  geom_vline(aes(xintercept=mean(x)),\n     color=\"red\", linetype=\"dashed\", lwd=1)\n\n\n\n\n\n\n\n\n\nYou do not need the rnorm function if you are provided a dataset with a numerical variable. The following code uses the customers dataset to do 2 examples of density plots with 2 numerical variables.\n\n\ncustomers &lt;- read.csv(\"data/customers.csv\")\n\nstr(customers)\n\n'data.frame':   200 obs. of  10 variables:\n $ CustID   : int  1530016 1531136 1532160 1532307 1532356 1532387 1533017 1533561 1533697 1533766 ...\n $ Sex      : chr  \"Female\" \"Male\" \"Male\" \"Male\" ...\n $ Race     : chr  \"Black\" \"White\" \"Black\" \"White\" ...\n $ BirthDate: chr  \"12/16/1986\" \"5/9/1993\" \"5/22/1966\" \"9/16/1964\" ...\n $ College  : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ HHSize   : int  5 5 2 4 5 2 3 5 3 2 ...\n $ Income   : int  53000 94000 64000 60000 47000 67000 84000 76000 42000 71000 ...\n $ Spending : int  241 843 719 582 845 452 153 1079 247 708 ...\n $ Orders   : int  3 12 9 13 7 9 2 23 3 4 ...\n $ Channel  : chr  \"SM\" \"TV\" \"TV\" \"SM\" ...\n\nggplot(customers, aes(Income)) + geom_density()\n\n\n\n\n\n\n\nggplot(customers, aes(Orders)) + geom_density(color = \"#745033\",fill=\"#740000\",alpha=.5)\n\n\n\n\n\n\n\n\n\n\nBoxplot\n\nA boxplot is a visual representation of data that shows central tendency (usually the median) and spread (usually the interquartile range) of a numeric variable for one or more groups.\nBoxplots are often used to compare the distribution of a continuous variable across several groups.\nA box plot allows you to:\n\nGraphically display the distribution of a data set.\nCompare two or more distributions.\nIdentify outliers in a data set.\n\n\n\n\n\nA Boxplot with Outliers on Left\n\n\n\nBoxplots include the following information:\n\nA line representing the median value.\nA box containing the middle 50% of values.\nWhiskers extending to 1.5 times the IQR.\nOutliers more than 1.5 times the IQR away from the median.\n\n\n\n\n\nA Boxplot with No Outliers\n\n\n\nThis boxplot above displays 5 summary values:\n\nS = smallest value.\nL = largest value.\nQ1 = first quantile = 25th percentile.\nQ2 = median = second quantile = 50th percentile.\nQ3 = third quantile = 75th percentile.\n\nFor example, use the GrowthFund Vector from the last lesson. It is executed again below.\n\n\nGrowthFund &lt;- c(-38.32, 1.71, 3.17, 5.99, 12.56, 13.47, 16.89, 16.96, 32.16, 36.29)\nGrowthFund &lt;- as.data.frame(GrowthFund)\n\n\nWe can use ggplot to retrieve our graph and associated numbers.\nThe outlier is visually depicted on the graph as -38.32.\n\n\nggplot(GrowthFund, aes(GrowthFund)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\nWe can add a little color to the plot with the fill parameter, but then we also need to be sure to turn off the legends in the geom_boxplot.\n\n\nggplot(GrowthFund, aes(GrowthFund)) + geom_boxplot(fill=\"red\")\n\n\n\n\n\n\n\n\n\nYou can add parameters to make this visualization more professional, but this gets you started. Be sure to look at some examples in the R community or on ChatGPT.\nAnother example below using the mtcars dataset.\n\n\nmtcars %&gt;%\n  ggplot(aes(x=\"\", y = mpg)) +\n  geom_boxplot(fill=\"lightgreen\") +\n  theme_minimal() \n\n\n\n\n\n\n\n\n\nsemTools::skew(mtcars$mpg) #normal\n\nskew (g1)        se         z         p \n    0.672     0.433     1.553     0.120 \n\nsemTools::kurtosis(mtcars$mpg) #mesokurtic\n\nExcess Kur (g2)              se               z               p \n         -0.022           0.866          -0.025           0.980 \n\n\n\nLooks like the mpg variable is quite normal with one potential outlier to the right, but no major signs of skewness or kurtosis.\nWe can also get a histogram of mpg and are able to make the same claims towards normality. You can see a slight pull to the right, but it is seemingly normal. A higher sample size could help here.\n\n\nggplot(mtcars, aes(mpg)) + geom_histogram(binwidth = 5, color=\"black\", fill=\"green\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "dataprep.html#graphs-for-two-variables-at-once",
    "href": "dataprep.html#graphs-for-two-variables-at-once",
    "title": "Data Preparation",
    "section": "Graphs for Two Variables At Once",
    "text": "Graphs for Two Variables At Once\n\nCombinations of 2 Variable Types for Graphing\n\nTwo categorical/ factor.\nOne categorical/ factor and one continuous/ numeric.\nTwo continuous/ numeric.\n\n\n\nBar Graphs for Two Categorical Variables\n\nThere are two formats available for bar charts:\n\nGrouped\nStacked\n\n\n\n\n# A tibble: 6 × 3\n# Groups:   vs, gear [6]\n     vs  gear     n\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1     0     3    12\n2     0     4     2\n3     0     5     4\n4     1     3     3\n5     1     4    10\n6     1     5     1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrouped Bar Graph\n\nGrouped bar graph allow comparison of multiple sets of data items, with a single color used to denote a specific series across all sets.\nFor example, we can look at both the vs and gear variables in the ggplot command.\n\nYou can do a little grouping and counting before you began to generate a new table with frequencies based on vs and gear variables. Once a new dataset object is made, you can make the graph with the geom_bar layer specifying the stat=“identity”.\nSince there are two variables, you can set the position to dodge to view the fill categorical variable side by side.\n(stat = “identity”) tells ggplot that the y values are already computed and should be used as-is for the heights of the bars. In this case, they are frequencies calculated in the countsDF dataset.\n\n\n\nmtcars &lt;- mtcars %&gt;% \n    mutate(vs=as.factor(vs)) %&gt;% \n    mutate(gear=as.factor(gear))\n\n\ncountsDF &lt;- mtcars %&gt;% \n    group_by(vs, gear) %&gt;%\n    count()\n\nsummary(countsDF)\n\n vs    gear        n         \n 0:3   3:2   Min.   : 1.000  \n 1:3   4:2   1st Qu.: 2.250  \n       5:2   Median : 3.500  \n             Mean   : 5.333  \n             3rd Qu.: 8.500  \n             Max.   :12.000  \n\nggplot(countsDF, aes(x = gear, y = n, fill = vs)) +\n     geom_bar(stat = \"identity\", position = \"dodge\") +\n     labs(title = \"Grouped Car Distribution by Gears and VS\",\n     x = \"Number of Gears\", y = \"Count\") +\n     theme_minimal()\n\n\n\n\n\n\n\n\n\n\nStacked Bar Graph\n\nA Stacked bar graph extends the standard bar graph from looking at numeric values across one categorical variable to two. Each bar in a standard bar graph is divided into a number of sub-bars stacked end to end, each one corresponding to a level of the second categorical variable.\nUsing ggplot, we can also stack these charts by removing the position = dodge statement.\n\n\nggplot(countsDF, aes(x = gear, y = n, fill = vs)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Stacked Car Distribution\",\n       x = \"Number of Gears\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nBar Graph for Continuous Across Groups\n\nIn comparison to a bar graph for a single categorical variable, a bar chart for a continuous variable across groups includes both a x and y axis. The continuous variable is put on the y axis, and the categorical (factor) variable is placed on the x axis showing the groups.\nTherefore, instead of counting data based on group, we can see another continuous variable based on group data.\nThe frequency data (i.e., counts) can be replaced with another numerical variable like mean.\nIn the below example, instead of counting observations per group, here, we took the average mpg (a continuous variable) based on groups of gear and vs and summarized the data into a variable avg_mpg. We then used that variable in a ggplot() command to create a unique chart to that above.\n\n\navg_mpg &lt;- mtcars %&gt;%\n  group_by(gear, vs) %&gt;%\n  summarise(mpg = mean(mpg, na.rm = TRUE))\n\n\nggplot(avg_mpg, aes(gear,\n  mpg, fill = vs)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  ggtitle(\"Average MPG by VS and Gear\")\n\n\n\n\n\n\n\n\n\nBelow, we can add color using the scale_fill_manual. Since there are two colors, we use the c() command to combine them together inside the layer.\n\n\nggplot(avg_mpg, aes(gear,\n     mpg, fill = vs)) +\n     geom_bar(stat = \"identity\", position = \"dodge\", color=\"black\") +  \n     ggtitle(\"Average MPG by VS and Gear\")+\n     scale_fill_manual(values=c(\"yellow\", \"brown\"))\n\n\n\n\n\n\n\n\n\n\n\nBoxplot for Continuous Across Groups\n\nA boxplot requires one continuous variable (like we did above). When we include an additional grouping variable, we get multiple boxplots, one for each group. This allows us to directly compare distributions.\nThe categorical variable should correctly be a factor data type before you begin.\nIn the example below, mpg is the continuous variable, and gear is the categorical variable.\nWe see 3 boxplots for three values of gear (3, 4, 5). ggplot() and geom_boxplot() are required components of the command. The scale_fill_manual() and theme_minimal() layers are optional ways to change the style and color.\n\n\nmtcars %&gt;%\n  ggplot(aes(x = gear, y = mpg, fill = gear)) +\n  geom_boxplot(show.legend = FALSE) +\n  scale_fill_manual(values = c(\"gray\", \"red\", \"blue\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nLets alter the functions above to depict mpg based on vs with categorical states 0 and 1.\n\n\nmtcars %&gt;%\n     ggplot(aes(x = vs, y = mpg, fill = vs)) +\n     geom_boxplot(show.legend = FALSE) +\n     scale_fill_manual(values = c(\"gray\", \"red\")) +\n     theme_minimal() \n\n\n\n\n\n\n\n\n\n\nScatterplot for Two Continuous Variables\n\nScatterplots\n\nA scatterplot is used to determine if two continuous variables are related.\n\nEach point is a pairing: \\((x_1, y_1),(x_2, y_2),\\) etc.\n\nOur goal with a scatterplot is to characterize the relationship by visual inspection. This includes determining if the relationship looks positive, negative, or not existent.\n\n\n\n\nScatterPlot Results\n\n\n\nSometimes, it is really clear how to characterize the relationship. Other times, additional statistical tests are needed to confirm the relationship (which we will go over in later lessons). This is true especially with big data, where the plot window can look like a giant blog of observations.\nLet’s work a clean example examining the relationship between income and the years of education one has had.\nThis plot has a clear positive trend, meaning that as one has more years of education, we see higher income. And similarly, as we see higher income, we also see more years of education. This means that a scatter can help characterize the relationship, and does not state that one variable is causing another to occur.\n\n\nEdu &lt;- read.csv(\"data/education.csv\")\nplot(Edu$Income ~ Edu$Education, ylab = \"Income\", xlab = \"Education\")\n\n\n\n\n\n\n\n\n\nWorking with ggplot instead of base R, we would use the following code.\n\nLayer 1: ggplot() command with aes() command directly inside of it pointing to x and y variables.\nLayer 2: geom_point() command to add the observations as indicators in the chart.\nLayer 3 or more: many other optional additions like labs (for labels) as shown below.\n\n\nggplot(Edu, aes(x=Education, y=Income)) +\n     geom_point() +\n     labs(y= \"Income\", x = \"Education\") \n\n\n\n\n\n\n\n\ngeom_point() has some parameters you can change like shape = where you can add depth to your chart. Some common shapes of geom_point are as follows.\n\n\n# shape = 0, square\n# shape = 1, circle\n# shape = 2, triangle point up\n# shape = 3, plus\n# shape = 4, cross\n# shape = 5, diamond\n# shape = 6, triangle point down\n# shape = 7, square cross\n# shape = 8, star\n# shape = 9, diamond plus\n# shape = 10, circle plus\n# shape = 11, triangles up and down\n# shape = 12, square plus\n# shape = 13, circle cross\n# shape = 14, square and triangle down\n# shape = 15, filled square\n# shape = 16, filled circle\n# shape = 17, filled triangle point-up\n# shape = 18, filled diamond\n\n\nFor instance, the code below changes the color, shape, and size of the geom_point().\n\n\nggplot(Edu, aes(x=Education, y=Income)) +\n     geom_point(color=\"#183028\", shape=18, size=10) +\n     labs(y= \"Income\", x = \"Education\") \n\n\n\n\n\n\n\n\n\ngeom_line() in R’s ggplot2 package is used to create line plots, which connect data points with straight lines. It is commonly used to visualize trends over time or continuous relationships between variables.\nggplot allows us to add a geom_line, which is helpful in drawing a line through the data. Here, I am also resetting the color off of the default value. You see this a lot on time series models like stock charts.\n\n\nggplot(Edu, aes(x=Education, y=Income)) +\n    geom_point(color=\"#183028\", shape=18, size=4) +\n    labs(y= \"Income\", x = \"Education\") +\n    geom_line(color=\"#789F90\")\n\n\n\n\n\n\n\n\n\nIn R’s ggplot2 package, geom_smooth() is used to add a trendline (also called a smoothing line or a regression line) to a plot. It fits a line or curve through your data points based on a smoothing method, allowing you to visualize the general relationship between the x and y variables. The trendline can help reveal patterns such as linear relationships or trends in noisy data. The trendline give us 2 parts:\n\nTrendline: This line represents the fitted relationship between the two variables, which could be linear, polynomial, or a more flexible curve depending on the smoothing method used.\nConfidence Interval: The shaded area (often gray by default) around the trendline shows the confidence interval, giving a sense of the uncertainty of the fit.\n\nWe can change our line to a geom_smooth line, which is considered a trendline to help us visualize the relationship between the variables.\n\n\nggplot(Edu, aes(x=Education, y=Income)) +\n    geom_point(color=\"#183028\", shape=18, size=4) +\n    labs(y= \"Income\", x = \"Education\") +\n    geom_smooth(color=\"#789F90\")\n\n\n\n\n\n\n\n\n\nWe can change the type of trendline. The most common is the to develop the trendline using the lm method, which stands for the linear method that we are going to learn in the Regression lesson. For now, lets insert _method=“lm” into our geom_smooth() later to see the change.\nThe gray band on a scatter plot in R usually represents the confidence interval around a fitted line when you plot it using geom_smooth() in ggplot2. This gray area visualizes the uncertainty or variability of the estimated regression line, providing a sense of how confident we are about the predictions at different points along the line.\n\n\nggplot(Edu, aes(x=Education, y=Income)) +\n    geom_point() +\n    labs(y= \"Income\", x = \"Education\") +\n    geom_smooth(method=\"lm\", color=\"#789F90\")\n\n\n\n\n\n\n\n\n\nUnlike geom_smooth(), which fits a trendline or smoothing line to data, geom_line() directly connects the raw data points in the order they appear (typically by the x-axis values). In business statistics class that teaches linear regression, we use more trendlines than geom_lines.\nLet’s look at a few more examples and see if the relationship is considered positive, negative, or not existent.\nBelow, we see a negative trend.\n\n\nggplot(mtcars, aes(x=disp, y=mpg))+ \n  geom_point() + \n  geom_smooth(method=\"lm\", color=\"#789F90\")\n\n\n\n\n\n\n\n\n\nIn regards to the hp variable, below, we see another negative trend.\n\n\nggplot(mtcars, aes(x=hp, y=mpg))+ geom_point() +\n  geom_smooth(method=\"lm\", color=\"#789F90\")\n\n\n\n\n\n\n\n\n\nIn regards to the qsec variable, below, we see a weak positive trend. This relationship would need to verified later on.\n\n\nggplot(mtcars, aes(x=qsec, y=mpg))+geom_point() + geom_smooth(method=\"lm\", color=\"#789F90\")\n\n\n\n\n\n\n\n\n\nThe plot() command also works when you do not have 2 continuous variables, and instead have one categorical variable paired with one continuous variable. However, the plot is not as adequate as others are in inferring the relationship from the variables.\nFor example, the plot below would be better served as a boxplot.\n\n\nplot(mtcars$mpg~ mtcars$cyl)  \n\n\n\n\n\n\n\nboxplot(mtcars$mpg~ mtcars$cyl)\n\n\n\n\n\n\n\n\n\nUsing ggplot, we would have the same issue. Since vs is a categorical variable, it does not look right when we use the geom_point() later.\n\n\nggplot(mtcars, aes(cyl, mpg)) + geom_point() + geom_smooth(method=\"lm\")\n\n\n\n\n\n\n\n\n\nInstead, we would want the geom_boxplot() layer like shown below. The geom_smooth() is also not an applicable layer to a boxplot and would need to be removed.\n\nWhen you create multiple boxplots in ggplot2 and one or more variables are numeric but not converted to factors, only one boxplot may show up because ggplot2 treats numeric variables as continuous. Boxplots group data by categorical variables, so if your variable is continuous, ggplot interprets it as a single category and produces only one boxplot.\nBelow, we still have an error.\n\n\nggplot(mtcars, aes(cyl, mpg)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\nSomething still is not quite right here, so we would need to make sure cyl is correctly a factor before making the boxplot. Now, we should see multiple boxplots, one for each categorical level. To fix this, you need to convert the grouping variable to a factor using as.factor() in your data, so ggplot will recognize it as a categorical variable and display multiple boxplots accordingly.\n\n\nmtcars &lt;- mtcars %&gt;% \n     mutate(cyl = as.factor(cyl))\nggplot(mtcars, aes(cyl, mpg)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nTry to Recreate\n\nYou try examples of scatterplots using the UScrime data set that is part of the MASS package to examine a few relationships using ggplot2. A few examples are below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSee what information you can take away from the scatterplots above and create some more to practice.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "dataprep.html#using-ai",
    "href": "dataprep.html#using-ai",
    "title": "Data Preparation",
    "section": "Using AI",
    "text": "Using AI\n\nUse the following prompts on a generative AI, like chatGPT, to learn more about data preparation activities.\nWhat is the difference between ordinal and nominal variables, and how can you recode these data types in R?\nHow can you use the filter() function to subset a dataset based on multiple conditions using & and | in R?\nHow does subsetting using square brackets [] differ from using the filter() function in R?\nWhat strategies can you use to handle missing data in R, and how does na.omit() differ from drop_na()?\nHow does the mutate() function help in transforming and creating new variables, and what are some practical examples?”\nWhat is the purpose of the group_by() function, and how does it interact with summarize() to create summary statistics in R?”\nExplain how you can use arrange() to sort a dataset by one or more variables and demonstrate sorting both in ascending and descending order.”\nWhy is the piping operator %&gt;% useful in R, and how does it improve the readability and structure of your code?\nHow would you use summarize() to calculate mean, median, and standard deviation for a numerical variable in R?\nUse the following prompts on a generative AI, like chatGPT, to learn more about data visualization capabilities in ggplot2.\nHow can I modify the appearance of a ggplot bar chart to include custom colors for each bar, and what are the best practices for choosing colors in data visualization?\nWhat is the role of layering in ggplot, and how can adding multiple layers, such as labels, themes, and lines, improve the readability of a plot?\nWhen should a density plot be used instead of a histogram, and how does each visualization help in understanding the distribution of continuous data?\nHow can I use a boxplot in R to identify and visualize outliers in my dataset, and what additional steps should I take to handle these outliers?\nHow can I create a scatter plot in ggplot to explore relationships between two continuous variables, and how do I add a trendline to help interpret the results?\nWhat are the steps for creating a grouped bar chart in ggplot, and how does this visualization help in comparing multiple categories or groups within a dataset?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "dataprep.html#summary",
    "href": "dataprep.html#summary",
    "title": "Data Preparation",
    "section": "Summary",
    "text": "Summary\n\nIn this lesson, we worked through the basics on data cleaning. Data cleaning is so important and there are so many ways to do it. Provided are some examples using popular functions in dplyr (under tidyverse).\nPractice many more examples with the help of ChatGPT and work towards constructing high-quality charts and graphs.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Preparation</span>"
    ]
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "Files, Functions, and Folders",
    "section": "",
    "text": "Reading/writing files (CSV, TXT)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Files, Functions, and Folders</span>"
    ]
  },
  {
    "objectID": "functions.html#navigating-directories",
    "href": "functions.html#navigating-directories",
    "title": "Files, Functions, and Folders",
    "section": "Navigating directories",
    "text": "Navigating directories",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Files, Functions, and Folders</span>"
    ]
  },
  {
    "objectID": "functions.html#functions-and-scope-making-own-functions",
    "href": "functions.html#functions-and-scope-making-own-functions",
    "title": "Files, Functions, and Folders",
    "section": "Functions and scope (Making own functions)",
    "text": "Functions and scope (Making own functions)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Files, Functions, and Folders</span>"
    ]
  },
  {
    "objectID": "functions.html#debugging-techniques",
    "href": "functions.html#debugging-techniques",
    "title": "Files, Functions, and Folders",
    "section": "Debugging techniques",
    "text": "Debugging techniques",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Files, Functions, and Folders</span>"
    ]
  },
  {
    "objectID": "numpypandas.html",
    "href": "numpypandas.html",
    "title": "Numpy and Pandas",
    "section": "",
    "text": "If Statements\nWelcome to your first lesson in Python control flow.\nIn programming and especially in analytics it’s not enough to simply store or calculate data. We also need to make decisions (“if this, then that”) and repeat actions (“keep doing this until done”).\nFor example:\nIn Python, two of the most common tools for this are:",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numpy and Pandas</span>"
    ]
  },
  {
    "objectID": "numpypandas.html#if-statements",
    "href": "numpypandas.html#if-statements",
    "title": "Numpy and Pandas",
    "section": "",
    "text": "Note\n\n\n\nReferences from Lutz, M. (2013). Learning Python (6th ed.). O’Reilly Media, Inc.\n\n\n\n\n\n\nA financial model might check if profit &gt; target, then apply a bonus.\nA data-cleaning script might keep looping while there are missing values.\n\n\n\nif statements → for decision making\nwhile loops → for repetition and automation\n\n\nLogical Conditions\nBefore we jump into Python syntax, let’s talk conceptually.\nA condition is something that can be either True or False.\nExamples of conditions in everyday life:\n\nIs it raining? → True or False\nIs my grade above 90? → True or False\nIs the customer balance less than zero? → True or False\n\nIn Python, we can write conditions using comparison operators:\n\n\n\nSymbol\nMeaning\nExample\nResult\n\n\n\n\n==\nequal to\n5==5\nTrue\n\n\n!=\nnot equal to\n5!=3\nTrue\n\n\n&gt;\ngreater than\n7&gt;3\nTrue\n\n\n&lt;\nless than\n2&lt;10\nTrue\n\n\n&gt;=\ngreater or equal\n5&gt;=5\nTrue\n\n\n&lt;=\nless or equal\n4&lt;=3\nFalse\n\n\n\n\n\nTrue\n\n\nFalse\n\n\nFalse\n\n\nThese Boolean results are what drive decision-making in code.\n\n\nBasic Syntax\nIn simple terms, the Python if statement selects actions to perform. Along with its if expression counterpart, it’s the primary selection tool in Python and represents much of the logic a Python program possesses. It’s also our first compound statement. Like all such statements, the if statement may contain other statements, including other ifs. In fact, Python lets you combine statements in a program both sequentially (so that they execute one after another), and in an arbitrarily nested fashion (so that they execute only under certain conditions, such as selections and loops).\nAn if statement tells Python: “Only run this block of code if a certain condition is true.”\nThink of it like a business rule: If revenue is above target, then give a performance bonus.\nSyntax:\n\n\nSimple Example\n\n\nBonus approved!\n\n\nBecause the condition revenue &gt; target is true, Python prints the message.\nTry changing revenue to a smaller number and re-run the code and see if it still prints the same thing.\n\n\nIf-Else\nWhat if we also want to say something when the condition is not true? That’s where else comes in.\n\n\nNeeds improvement.\n\n\nPython checks the if condition first. If it’s false, it runs the else block instead.\n\n\nMultiple Conditions\nWhen you have more than two possibilities, use elif (“else if”).\n\n\nGrade: B\n\n\nPython checks the conditions in order and runs the first one that’s true.\n\n\nCombining Conditions\nYou can combine multiple conditions using:\n\nand → both must be true\nor → at least one is true\nnot → reverses true/false\n\n\n\nEligible for credit card\n\n\n\n\nNested Statements\nYou can also put one if inside another for more complex logic.\n\n\nYou can enter.\n\n\nThis structure is common in data workflows — checking multiple business rules in sequence.\n\n\nPractice\nWrite your own example:\n\nAsk for a test score (input)\nPrint “Excellent” if 90+, “Good” if 80–89, otherwise “Needs Improvement”",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numpy and Pandas</span>"
    ]
  },
  {
    "objectID": "numpypandas.html#while-loops",
    "href": "numpypandas.html#while-loops",
    "title": "Numpy and Pandas",
    "section": "While Loops",
    "text": "While Loops",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numpy and Pandas</span>"
    ]
  },
  {
    "objectID": "numpypandas.html#loop-basics",
    "href": "numpypandas.html#loop-basics",
    "title": "Numpy and Pandas",
    "section": "Loop Basics",
    "text": "Loop Basics\nPython’s while statement is the most general iteration construct in the language. In simple terms, it repeatedly executes an associated block of statements as long as a test at the top keeps evaluating to a true value. It is called a “loop” because control keeps looping back to the start of the statement until the test becomes false. When the test does become false, control passes to the statement that follows the while block. The net effect is that the loop’s body is executed repeatedly while the test at the top is true. If the test is false to begin with, the body never runs and the while statement is skipped.\nBasically sometimes we need to repeat a task several times — or until a condition changes.\nExample in plain language: While there are still customers in line → keep serving.\nIn Python the syntax is:\nThe loop runs again and again as long as the condition is true.\n\n\nHello, world!\nHello, world!\nHello, world!\n\n\nThis prints three lines because:\n\nStart: count = 1\nEach loop: print, then add 1\nStop when count &lt;= 3 becomes false\n\n\nInfinite Loops\nIf the condition never becomes false, the loop never ends.\nAlways make sure something inside your loop changes the condition.\n\n\nLoop Control\nIn Python we can control loop flow manually.\nbreak: Jumps out of the closest enclosing loop (past the entire loop statement)\ncontinue: Jumps to the top of the closest enclosing loop (to the loop’s header line)\npass: Does nothing at all: it’s an empty statement placeholder\nLoop else block: Runs if and only if the loop is exited normally (i.e., without hitting a break)\nbreak and continue statements can appear anywhere inside the while (or per ahead, for) loop’s body, but they are usually coded further nested in an if test to take action in response to some condition.\nbreak → exit the loop early\n\n\n1\n2\n\n\ncontinue → skip this iteration\n\n\n1\n2\n4\n5\n\n\n\n\nWhile-Else\nA while loop can also have an else block that runs when the loop ends normally (without break).\n\n\nx = 3\nx = 2\nx = 1\nLoop finished!\n\n\n\n\nCombined Example\nWe can combine both ideas to make small, smart programs.\nExplanation:\n\nThe while loop keeps asking until the user guesses correctly.\nThe if inside checks how the guess compares to the secret number.\n\n\n\nSummary\n\n\n\nConcept\nPurpose\nExample\n\n\n\n\nif\nRun code when condition is true\nif x &gt; 5:\n\n\nelse\nRun code when condition is false\nelse:\n\n\nelif\nTest another condition\nelif x == 5:\n\n\nwhile\nRepeat while condition is true\nwhile x &lt; 10:\n\n\nbreak\nExit the loop early\nbreak\n\n\ncontinue\nSkip current iteration\ncontinue",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numpy and Pandas</span>"
    ]
  },
  {
    "objectID": "numpypandas.html#numpy",
    "href": "numpypandas.html#numpy",
    "title": "Numpy and Pandas",
    "section": "Numpy",
    "text": "Numpy",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numpy and Pandas</span>"
    ]
  },
  {
    "objectID": "numpypandas.html#pandas",
    "href": "numpypandas.html#pandas",
    "title": "Numpy and Pandas",
    "section": "Pandas",
    "text": "Pandas",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numpy and Pandas</span>"
    ]
  },
  {
    "objectID": "numpypandas.html#data-cleaning",
    "href": "numpypandas.html#data-cleaning",
    "title": "Numpy and Pandas",
    "section": "Data Cleaning",
    "text": "Data Cleaning",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numpy and Pandas</span>"
    ]
  },
  {
    "objectID": "sql.html",
    "href": "sql.html",
    "title": "Introduction to SQL in Python",
    "section": "",
    "text": "Installing MySQL\nBooks:",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#sql-syntax-notes",
    "href": "sql.html#sql-syntax-notes",
    "title": "Introduction to SQL in Python",
    "section": "SQL syntax notes:",
    "text": "SQL syntax notes:\n\nSQL has a flexible and easy-to-read syntax.\n\nA semicolon (;) marks the end of a SQL statement, which is especially helpful when several statements appear in sequence.\nSQL keywords (such as SELECT, FROM, and WHERE) and the names of tables and columns are not case sensitive, so formatting is up to the user.\nSQL commands can also be written on a single line or spread across multiple lines for clarity.\n\nThese features make SQL straightforward to write, easy to interpret, and adaptable to many coding styles.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#creating-a-database-in-sql",
    "href": "sql.html#creating-a-database-in-sql",
    "title": "Introduction to SQL in Python",
    "section": "Creating a Database in SQL:",
    "text": "Creating a Database in SQL:\nUse CREATE DATABASE to create a new database using SQL\nCREATE DATABASE DBName;\n\nCreating tables, columns, and keys in the database\n\nUSE specifies that database you will be using\nCREATE TABLE creates a table in your specified database\nnew column names are followed by the column data type\n\nUSE DBName;\nCREATE TABLE TName\n(Column1 data type NOT NULL, (if mandatory)\nColumn 2 data type, (if optional)\n…\nColumn data type NOT NULL, \nPRIMARY KEY (Column1),\nFOREIGN KEY (Column) references OtherTable (column));\n\n\nSQL data types:\n\nCHAR(n): fixed length n character string\nVARCHAR(n): variable length character string with a maximum size of n characters\nINT: integer\nNUMERIC(x,y): number with x digits, y of which are after the decimal point\nDATE: date values (year, month, day)\n\n\n\nAltering a Table\nUse ALTER TABLE to alter column in a table\n\nADD adds columns\nDROP drops columns\n\nALTER TABLE tablename ADD (Column data type)\nALTER TABLE tablename DROP (Column);\n\n\nInsert values into a table\nUse INSERT INTO tablename VALUES to insert data into the rows of a table\nINSERT INTO tablename VALUES (column1, column2, …);\nFor example, if we want to add a row into a table, students, with the columns StudentID, FirstName, LastName, DateOfEnrollment, Email:\nINSERT INTO students VALUES (1, ‘Maria’, ‘Gonzales’, 2024-08-15’, email@example.com);\n\n\nDelete from a table\nUse DELETE FROM\nDELETE FROM tablename \nWHERE condition;\n\n\nModify existing records within a table\nUse UPDATE\nUPDATE tablename \nSET columnname = value\nWHERE condition (if applicable);",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#using-the-select-statement",
    "href": "sql.html#using-the-select-statement",
    "title": "Introduction to SQL in Python",
    "section": "Using the SELECT Statement",
    "text": "Using the SELECT Statement\nSELECT is used to select (retrieve) data from a database table.\nSELECT requires two pieces of information:\n\nWhat to SELECT\nWhere to SELECT it from\n\nSELECT column\nFROM table;\n\nRetrieve a Single Column\nSELECT prod_name\nFROM Products\n\n\nRetrieve Multiple Columns\nList columns in a comma delimited list\nSELECT prod_id, prod_name, prod_price\nFROM Products;\n\n\nRetrieve All Columns\nUse * to retrieve all columns from a table\nSELECT *\nFROM Products;\n\n\nRetrieve Distinct Rows\n\nAfter SELECT, use DISTINCT to select distinct values\n\nSELECT DISTINCT prod_name\nFROM Products\n\n\nLimit Retrieved Data\n\nUse LIMIT following the FROM statement to limit the amount of data retrieved\n\nSELECT prod_name\nFROM Products\nLIMIT 5;",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#order-by",
    "href": "sql.html#order-by",
    "title": "Introduction to SQL in Python",
    "section": "ORDER BY",
    "text": "ORDER BY\nTo specify sort order, add ORDER BY to your SELECT statement.\nORDER BY requires one piece of information:\n\nThe column to sort by\nOptionally, you may also specify multiple sort columns as well as sort direction\n\nSELECT column\nFROM table\nORDER BY column ASC|DESC\n\nSort by One Column\nSELECT prod_name\nFROM Products\nORDER BY prod_name;\n\n\nSort by Multiple Columns\nSelect column names in a comma delimited list, and provide a list of columns to order by that are comma delimited.\nSELECT prod_id, prod_name, prod_price\nFROM Products\nORDER BY prod_price, prod_name;\n\n\nSpecify Sort Direction\nUse ASC or DESC\n\nThe default is ASC, however it is best practice to provide an explicit sort order\n\nSELECT prod_id, prod_name, prod_price\nFROM Products\nORDER BY prod_price, prod_name DESC;",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#using-where",
    "href": "sql.html#using-where",
    "title": "Introduction to SQL in Python",
    "section": "Using WHERE",
    "text": "Using WHERE\nTo filter returned data, add WHERE to your SELECT statement\nWHERE requires one piece of information:\n\nThe filter condition (a statement that is tested against each row)\n\nGoes after FROM and before ORDER BY in the SELECT statement\nSELECT column\nFROM table\nWHERE condition\nORDER BY column ASC|DESC;\n\nWHERE Clause Operators:\n\nEquality: =\nNon-equality: != or &lt;&gt;\nLess than: &lt;\nLess than or equal to: &lt;=\nGreater than: &gt;\nGreater than or equal to: &gt;=\n\nExample:\nSELECT prod_name, prod_price\nFROM Products\nWHERE prod_price &lt; 10;\n\n\nFilter using a range using WHERE:\nUse WHERE column BETWEEN to filter using a range:\nSELECT prod_name, prod_price\nFROM Products\nWHERE prod_price BETWEEN 5 AND 10;\n\n\nFilter for No Value\nNull is a special keyword that means that a column has no value\n\nNULL is not the same as “”\n\nWHERE can be used with NULL to find (or exclude) columns with no value\nSELECT prod_name\nFROM Products\nWHERE prod_price IS NULL;\nThis will return only the rows that have a null value in a specified column",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#combine-where-clauses",
    "href": "sql.html#combine-where-clauses",
    "title": "Introduction to SQL in Python",
    "section": "Combine WHERE clauses",
    "text": "Combine WHERE clauses\nWHERE clauses can be combined using\n\nAND (both conditions must be true)\nOR (one or more conditions must be true)\n\nSELECT prod_name, prod_price, prod_id\nFROM Products\nWHERE prod_id = 'DLL01'\nAND prod_price &lt;= 4;\n\nOrder of Evaluation\nAND always gets evaluated before OR in a where clause unless parentheses are used to explicitly change the order of evaluation.\nSELECT prod_name, prod_price\nFROM Products\nWHERE (prod_id = 'DLL01' OR prod_id = 'BRS01') AND prod_price &gt;= 10\nThe use of parentheses forces a higher level of evaluation.\nBest practice is to always use parentheses to explicitly control order of evaluation.\n\n\nFilter using IN\nIN is used to specify one or more values to be matched\nIN values are comma delimited\n\nIN (1,2,3)\n\nSELECT prod_name, prod_price\nFROM Products\nWHERE prod_id IN ('DLL01', 'BRS01') \nORDER BY prod_name; \nWhy use IN?:\n\nhelps to simplify order of evaluation\nuseful for filtering for multiple values\nuseful in subqueries\n\n\n\nNegate using NOT\nNOT is used to negate a WHERE clause NOT is inserted before the condition:\nSELECT prod_price\nFROM Products\nWHERE NOT prod_price = 3.49; \n\n\nFilter using LIKE\nUse LIKE to search using a wildcard\n\n% to match zero or more characters\n_ to match a single character\n\nSELECT prod_id, prod_name\nFROM Products\nWHERE prod_name LIKE 'F%';\nWill return matched text that begins with the letter F in the column prod_name. The % after the F indicates that any sequence of characters can follow.\nSELECT product_name\nFROM Products\nWHERE product_id LIKE '_A%';\nThis query would match ‘BA123’, ‘CA456’, etc.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#creating-caclulated-fields",
    "href": "sql.html#creating-caclulated-fields",
    "title": "Introduction to SQL in Python",
    "section": "Creating Caclulated Fields",
    "text": "Creating Caclulated Fields\n\nUse Concatenation\nConcatenation is used to appends columns to each other.\n\nConcat()\n\nSELECT Concat(prod_name, ' (', prod_country, ')')\nFROM Products;\nThis query returns you prod_name (prod_country). For example, an output may be Teddy Bear (USA).\n\n\nUsing Aliases\nAliases are used to name database objects:\n\nTables\nColumns\nCalculated Fields\n\nTo create a column alias, you follow a column name or expression with either:\n\nan alias name -the AS keyword and an alias name\n\nSELECT Concat(prod_name, ' (', prod_country, ')') prod_title\nFROM Products;\nOR\nSELECT Concat(prod_name, ' (', prod_country, ')') AS prod_title\nFROM Products;\n\n\nPerform Mathematical Calculations\nSELECT statements can be used to perform mathematical calculations:\n\nAddition: +\nSubtraction: -\nMultiplication: *\nDivision: /\n\nWhen performing calculations, aliases can be used to name the results\nSELECT prod_id, quantity, item_price, quantity * item_price AS expanded_price\nFROM OrderItems\nWHERE order_num = 20008;\n\n\nUsing String Functions\nCommon functions include:\n\nLEFT() and RIGHT() to extract parts of a string\nLENGTH() to obtain the length of a string\nLOWER() and UPPER() to convert string case\nTRIM(), LTRIM(), and RTRIM to trim strings\n\nSELECT prod_name, UPPER(prod_name) AS prod_name_upcase\nFROM Products\nORDER BY prod_name;\nReturns to columns, prod_name and prod_name in all capital letters.\n\n\nUsing Date Functions\nDate functions are used to:\n\nExtract parts of dates and times\nCompare date and time values\nFormat dates and times for locale and language specific display\n\nSELECT order_num\nFROM orders\nWHERE YEAR(order_date) = 2012;\n\n\nUsing aggregate functions\nFrequently used Aggregate Functions are:\n\nAVG()\nCOUNT()\n\ncan be used with a column name or with *\n\nMAX()\nMIN()\nSUM()\n\nSELECT AVG(prod_price) AS avg_price, MIN(prod_price) AS price_min\nFROM Products;\nThis query returns the average prod_price and the minimum prod_price.\nSELECT COUNT(*) AS num_cust\nFROM Customers;\nThis query returns the total number of rows in the Customers table.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#using-group-by",
    "href": "sql.html#using-group-by",
    "title": "Introduction to SQL in Python",
    "section": "Using GROUP BY",
    "text": "Using GROUP BY\nGROUP BY is used to summarize data by group\n\nA group is a unique column value\nGoes before ORDER BY and after WHERE\n\nSELECT column\nFROM table\nWHERE condition\nGROUP BY column\nORDER BY column ASC|DESC;\nSELECT vend_id, COUNT(*) AS num_prods\nFROM Products\nGROUP BY vend_id;",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#using-having",
    "href": "sql.html#using-having",
    "title": "Introduction to SQL in Python",
    "section": "Using HAVING",
    "text": "Using HAVING\nHAVING is used to filter results at the group level\n\nHAVING is passed a filter statement, just like WHERE\nGoes after GROUP BY and before ORDER BY\n\nSELECT column\nFROM table\nWHERE condition\nGROUP BY column\nHAVING condition\nORDER BY column ASC|DESC;\n\nWHERE versus HAVING\n\nWHERE filters before data is grouped, and HAVING filters after data is grouped.\nRows that are eliminated by a WHERE clause will not be included in the group\n\nSELECT vend_id, COUNT(*) AS num_prods\nFROM Products\nWHERE prod_price &gt;= 4\nGROUP BY vend_id\nHAVING COUNT(*) &gt;= 2;",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#using-subqueries-with-where",
    "href": "sql.html#using-subqueries-with-where",
    "title": "Introduction to SQL in Python",
    "section": "Using Subqueries with WHERE",
    "text": "Using Subqueries with WHERE\n\nA WHERE clause filters data retrieved by SELECT\nSubqueries allow the results of one query to be used as the filter conditions for another query\n\nSELECT cust_id\nFROM ORDERS\nWHERE order_num IN (SELECT order_num\n                    FROM OrderItems\n                    WHERE prod_id = 'RGAN01');\nThis query is selecting customer ID from orders where the order number is in whatever the results are from the subquery select statement.\n\nUsing Subqueries as Calculated Fields\nThis example, uses fully qualified table names to prevent ambiguity.\nSELECT cust_name, cust_state,\n      (SELECT COUNT(*) \n       FROM Orders\n       WHERE Orders.cust_id = Customers.cust_id) AS orders\nFROM Customers\nORDER BY cust_name;",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#joining-tables",
    "href": "sql.html#joining-tables",
    "title": "Introduction to SQL in Python",
    "section": "Joining Tables",
    "text": "Joining Tables\n\nCreate a Basic Join\nTables are usually joined by keys\n\nA primary key uniquely identifies every row in a table -There can only ever be one of each primary key value\nA foreign key in a table contains the primary key value of a required table\n\nMultiple rows in table can have the same foreign key value\n\n\nThe Simplest join requires two tables that share a key which are tested for equality\n\nPrimary key in one table\nForeign key in another table\n\nThis is called an INNER JOIN\nSELECT vend_name, prod_name, prod_price\nFROM Vendors INNER JOIN Products \n  ON Vendors.vend_id = Products.vend_id;\n\n\nJoin Multiple Tables\nSELECT prod_name, vend_name, prod_price, quantity\nFROM OrderItems, Products, Vendors\nWHERE Products.vend_id = Vendors.vend_id\n  AND OrderItems.prod_id = Products.prod_id\n  AND order_num = 20007;",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#creating-advanced-joins",
    "href": "sql.html#creating-advanced-joins",
    "title": "Introduction to SQL in Python",
    "section": "Creating Advanced Joins",
    "text": "Creating Advanced Joins\n\nUsing Table Aliases\nSimilar to how aliases are used to name or rename columns, aliases can also be used to rename tables\nSELECT column\nFROM table AS alias;\n\n\nCreating a Self Join\n\nA self join is used to join a table to itself.\nWhen using self joins aliases must be used to uniquely name each table instance\n\nSELECT c1.cust_id, c1.cust_name, c1.cust_contact\nFROM Customers AS c1, Customers AS c2\nWHERE c1.cust_name = c2.cust_name \n  AND c2.cust_contact = 'Jim Jones';\n\n\nCreating an Outer Join\n\nAn INNER JOIN joins two tables and only retrieves rows that have related rows in the other table.\nAn outer join makes it possible to retrieve all the rows from one table regardless of whether or not they have related rows in the other table.\n\nLEFT OUTER JOIN or RIGHT OUTER JOIN\n\n\nSELECT Customers.cust_id, Orders.order_num\nFROM Customers LEFT OUTER JOIN Orders \n  ON Customers.cust_id = Orders.cust_id;\nSELECT Customers.cust_id, Orders.order_num\nFROM Customers RIGHT OUTER JOIN Orders \n  ON Customers.cust_id = Orders.cust_id;",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#combining-queries",
    "href": "sql.html#combining-queries",
    "title": "Introduction to SQL in Python",
    "section": "Combining Queries",
    "text": "Combining Queries\n\nUsing a UNION\nThe UNION operator combines the result sets of two or more SELECT statements into a single, distinct result set.\nTo use a UNION, orovide both complete queries with the keyword UNION between them\nSELECT cust_name, cust_contact, cust_email\nFROM Customers\nWHERE cust_state IN ('IL', 'IN', 'MI')\nUNION\nSELECT cust_name, cust_contact, cust_email\nFROM Customers\nWHERE cust_name = 'Fun4All';\nUNION rules:\n\nAll queries must have the same columns\nColumn order need not be the same\nColumn types need not be the same but must be compatible\n\n\n\nIncluding/Excluding Duplicates\n\nUnions automatically exclude duplicates\nTo include all rows, even duplicates, use UNION ALL\n\nSELECT cust_name, cust_contact, cust_email\nFROM Customers\nWHERE cust_state IN ('IL', 'IN', 'MI')\nUNION ALL\nSELECT cust_name, cust_contact, cust_email\nFROM Customers\nWHERE cust_name = 'Fun4All';\n\n\nSorting Combined Queries\nWhen using a UNION, only one ORDER BY may be used\nSELECT cust_name, cust_contact, cust_email\nFROM Customers\nWHERE cust_state IN ('IL', 'IN', 'MI')\nUNION ALL\nSELECT cust_name, cust_contact, cust_email\nFROM Customers\nWHERE cust_name = 'Fun4All'\nORDER BY cust_name, cust_contact;",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "sql.html#the-select-statement-revisited",
    "href": "sql.html#the-select-statement-revisited",
    "title": "Introduction to SQL in Python",
    "section": "The SELECT Statement Revisited",
    "text": "The SELECT Statement Revisited\nSELECT column\nFROM table(s)\n  ON join\nGROUP BY column\nHAVING condition\nUNION\nORDER BY column ASC|DESC;",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to SQL in Python</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "In this online book, we went over information to make sure you had some basics to really start learning R. This journey began with the basics of R, emphasizing that while multiple methods exist to achieve the same results in R, it’s crucial to find the approach that works best for you. As we learn R, you will get used to doing things your way to be able to slice and evaluate the data to find rich information from the data sets we look at. As long as the data was handled properly, it does not matter how we reach our goal using R as long as we do it ourselves.\nMastering R allows you to effectively clean, analyze, and interpret data, unlocking valuable insights from various datasets. We explored the essential practice of data cleaning, learning various techniques and popular functions within the dplyr package under the tidyverse. Proper data cleaning ensures the integrity and accuracy of your analysis. We delved into skewness, kurtosis, variables, and scales of measurement, focusing on summarizing qualitative and quantitative data. Visualizations were introduced as powerful tools to describe variables and uncover patterns in the data.\nWe examined basic probability rules were covered alongside binomial and continuous distributions. We examined the normal distribution, its limitations, and methods for transforming non-normal variables. Central limit theorem is discussed with the Empirical rule alongside normal distributions.\n\nThis book has equipped you with the foundational skills needed to handle data before deeply analyzing it using R. Remember, the key to mastering these techniques lies in consistent practice and finding the methods that best suit your analytical style.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Recommended Further Reading Materials",
    "section": "",
    "text": "Forta, B. (2015, July). Learning SQL [Video]. Pearson / O’Reilly. https://learning.oreilly.com/videos/learning-sql/9780134193700/9780134193700-LSQL_00_Introduction/\nHarris, J. K. (2019). Statistics with R: Solving problems using real-world data. SAGE Publications.\nJaggia, S., & Kelly, A. (2018). Business statistics: Communicating with numbers (3rd ed.). McGraw-Hill Education.\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An introduction to statistical learning: With applications in R. Springer. Springer Texts in Statistics.\nLutz, M. (2013). Learning Python (6th ed.). O’Reilly Media, Inc.\nZhao, A. (2021). SQL Pocket Guide (4th ed.). O’Reilly Media. Retrieved from https://learning.oreilly.com/library/view/sql-pocket-guide/9781492090397/ch03.html.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Recommended Further Reading Materials</span>"
    ]
  },
  {
    "objectID": "mathnotation.html",
    "href": "mathnotation.html",
    "title": "Math Notation and Probability in R",
    "section": "",
    "text": "Math notation",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#math-notation",
    "href": "mathnotation.html#math-notation",
    "title": "Math Notation and Probability in R",
    "section": "",
    "text": "sigma, pi, functions, exponents, logic rules",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#creating-a-new-function-vs-using-a-built-in-function",
    "href": "mathnotation.html#creating-a-new-function-vs-using-a-built-in-function",
    "title": "Math Notation and Probability in R",
    "section": "Creating a new function vs using a built in function",
    "text": "Creating a new function vs using a built in function\n\nFunction_name: The name you assign to your function (e.g., my_sum)\n&lt;- Assignment operator: stores the function under the name\nfunction(): Declares that you’re defining a function\narguments: Inputs the function expects (e.g., x, y)\n{} The body: code that runs when the function is called\nreturn(): Specifies the value that gets returned (can also omit this in simple cases)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#sample-variance",
    "href": "mathnotation.html#sample-variance",
    "title": "Math Notation and Probability in R",
    "section": "Sample Variance",
    "text": "Sample Variance\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n - 1}\n\\]\n\nMeasures data spread.\nBasis for standard deviation.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#weighted-average",
    "href": "mathnotation.html#weighted-average",
    "title": "Math Notation and Probability in R",
    "section": "Weighted Average",
    "text": "Weighted Average\n\\[\n\\bar{x}_w = \\frac{\\sum_{i=1}^n w_i x_i}{\\sum_{i=1}^n w_i}\n\\]\n\nValues weighted by importance (e.g., confidence or revenue).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#dot-product-vectors",
    "href": "mathnotation.html#dot-product-vectors",
    "title": "Math Notation and Probability in R",
    "section": "Dot Product (Vectors)",
    "text": "Dot Product (Vectors)\n\\(x \\cdot w = \\sum_{i=1}^n x_i w_i\\)\n\nCore in machine learning models and matrix operations.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#sum-of-squared-errors-sse",
    "href": "mathnotation.html#sum-of-squared-errors-sse",
    "title": "Math Notation and Probability in R",
    "section": "Sum of Squared Errors (SSE)",
    "text": "Sum of Squared Errors (SSE)\n\\[\\text{SSE} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\\]\n\nUsed in regression model evaluation\n\n\nx &lt;- c(2, 4, 6, 8, 9)\ny &lt;- c(1, 3, 4, 10, 8)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#covariance",
    "href": "mathnotation.html#covariance",
    "title": "Math Notation and Probability in R",
    "section": "Covariance",
    "text": "Covariance\n\\[ \\text{Cov}(X, Y) = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{n - 1}\\]\n\\[\nr = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\n\\]\n\nMeasures linear relationship between two variables\nCov(X, Y) is the covariance between variables ( X ) and ( Y ).\n( _X ) and ( _Y ) are the standard deviations of ( X ) and ( Y ), respectively.\nr ranges from −1 (perfect negative) to +1 (perfect positive).\nDescribes both strength and direction of a linear relationship.\nUnitless — unaffected by changes in scale or units.\n\n\nx &lt;- c(2, 4, 6, 8, 9)\ny &lt;- c(1, 3, 4, 10, 8)\n\nmean_x &lt;- mean(x)\nmean_y &lt;- mean(y)\n\ncov_xy &lt;- sum((x-mean_x)*(y-mean(y)))/(5-1); cov_xy\n\n[1] 9.8\n\ncor_xy &lt;- cov_xy/(sd(x)*sd(y)); cor_xy\n\n[1] 0.9246106",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#mean-absolute-error-mae",
    "href": "mathnotation.html#mean-absolute-error-mae",
    "title": "Math Notation and Probability in R",
    "section": "Mean Absolute Error (MAE)",
    "text": "Mean Absolute Error (MAE)\n\\(\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n | y_i - \\hat{y}_i|\\)\n\nMeasures average size of prediction error.\nLess sensitive to outliers than SSE.\n\nGiven:\n\nActual values: 3, 5, 2, 7\n\nPredicted values: 2, 6, 2.5, 8\n\nAbsolute Errors: \\[|3 - 2| = 1,\\quad |5 - 6| = 1,\\quad |2 - 2.5| = 0.5,\\quad |7 - 8| = 1\\]\nMAE Calculation:\n\\[\n\\text{MAE} = \\frac{1 + 1 + 0.5 + 1}{4} = \\frac{3.5}{4} = 0.875\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#mean-squared-error-mse",
    "href": "mathnotation.html#mean-squared-error-mse",
    "title": "Math Notation and Probability in R",
    "section": "Mean Squared Error (MSE)",
    "text": "Mean Squared Error (MSE)\n\\(\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\\)\n\nMeasures the average of the squared differences between actual and predicted values.\n\nA common metric to evaluate the accuracy of regression models.\n\nSensitive to large errors due to squaring.\n\nSquared Errors:\n\\[\n(3 - 2)^2 = 1,\\quad (5 - 6)^2 = 1,\\quad (2 - 2.5)^2 = 0.25,\\quad (7 - 8)^2 = 1\n\\]\nMSE Calculation:\n\\[\n\\text{MSE} = \\frac{1 + 1 + 0.25 + 1}{4} = \\frac{3.25}{4} = 0.8125\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#log-likelihood-logistic-regression",
    "href": "mathnotation.html#log-likelihood-logistic-regression",
    "title": "Math Notation and Probability in R",
    "section": "Log-Likelihood (Logistic Regression)",
    "text": "Log-Likelihood (Logistic Regression)\n\\(\\ell(\\beta) = \\sum_{i=1}^n [ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i)]\\)\n\nQuantifies how likely predicted probabilities match observed outcomes\n\nMaximized to estimate model parameters \\(\\beta\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#k-means-clustering-objective",
    "href": "mathnotation.html#k-means-clustering-objective",
    "title": "Math Notation and Probability in R",
    "section": "K-Means Clustering Objective",
    "text": "K-Means Clustering Objective\n\\(J = \\sum_{i=1}^k \\sum_{x \\in C_i} \\| x - \\mu_i \\|^2\\)\n\nK-Means Clustering is an unsupervised machine learning algorithm used to group data points into k clusters based on similarity, essentially measuring the within-cluster variance.\n\nEach data point is assigned to the cluster with the nearest centroid (mean of the cluster).\nThe algorithm aims to minimize the total within-cluster variance — that is, the distance between points and their cluster centers.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#euclidean-distance",
    "href": "mathnotation.html#euclidean-distance",
    "title": "Math Notation and Probability in R",
    "section": "Euclidean Distance",
    "text": "Euclidean Distance\n\\[\nd_{\\text{euclidean}}(x, y) = \\sqrt{\\sum_{i=1}^n (x_i - y_i)^2}\n\\]\n\nMeasures the straight-line (as-the-crow-flies) distance between two points in n-dimensional space.\nCommonly used in clustering, nearest neighbor models, and geometry.\nSensitive to scale — variables should often be standardized.\nExample: \\(d = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2}\\)\nEuclidean: \\(\\sqrt{(5 - 2)^2 + (5 - 1)^2} = \\sqrt{9 + 16} = \\sqrt{25} = 5\\)\n\n\n\n\nEuclidean Distance",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#manhattan-distance",
    "href": "mathnotation.html#manhattan-distance",
    "title": "Math Notation and Probability in R",
    "section": "Manhattan Distance",
    "text": "Manhattan Distance\n\\[\nd_{\\text{manhattan}}(x, y) = \\sum_{i=1}^n |x_i - y_i|\n\\]\n\nMeasures distance along axes only — like navigating a grid of city streets.\nMore robust to outliers than Euclidean distance.\nUsed in clustering, especially when features are not continuous or are sparse (e.g., in NLP or recommender systems).\nExample: \\(d = |x_1 - y_1| + |x_2 - y_2|\\)\nManhattan: \\(|5 - 2| + |5 - 1| = 3 + 4 = 7\\)\n\n ## Looking at distance measures with a Dataset\n\ndata &lt;- read.csv(\"data/Universities.csv\")\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.5.1\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Remove the School column (non-numeric) and type\nnumericData &lt;- select(data, -School, -Type)\nstr(numericData)\n\n'data.frame':   7 obs. of  5 variables:\n $ Median.SAT          : int  1315 1220 1240 1176 1300 1281 1255\n $ Acceptance.Rate     : num  0.22 0.53 0.36 0.37 0.24 0.24 0.56\n $ Expenditures.Student: int  26636 17653 17554 23665 25703 24201 18847\n $ Top.10..HS          : int  85 69 58 95 78 80 70\n $ Graduation..        : int  93 80 88 86 90 90 84\n\n# Compute Euclidean distance\ndistance_matrix &lt;- dist(numericData, method = \"euclidean\")\n# View the result\ndistance_matrix\n\n          1         2         3         4         5         6\n2 8983.5260                                                  \n3 9082.3512  101.9119                                        \n4 2974.2749 6012.2202 6111.4475                              \n5  933.1516 8050.4088 8149.2457 2041.8435                    \n6 2435.2443 6548.3010 6647.1632  546.4083 1502.1215          \n7 7789.2507 1194.5200 1293.1489 4818.7129 6856.1550 5354.0758\n\n#compare to scaled\ndata_scaled &lt;- scale(numericData)\ndistance_matrix_scaled &lt;- dist(data_scaled, method = \"euclidean\")\ndistance_matrix_scaled\n\n          1         2         3         4         5         6\n2 4.9783077                                                  \n3 3.8960487 2.4226692                                        \n4 3.6464470 3.3284720 3.7240741                              \n5 0.9940707 4.1405757 3.0998943 3.2511808                    \n6 1.2465444 3.8512824 2.8119917 2.8300258 0.5748688          \n7 4.1557883 1.2321260 2.0224459 3.2508826 3.3959798 3.1620968",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#function-basics",
    "href": "mathnotation.html#function-basics",
    "title": "Math Notation and Probability in R",
    "section": "Function Basics",
    "text": "Function Basics\n\nFunction Properties\n\nInjective: No two inputs map to the same output\nSurjective: Every element in the codomain is mapped to by some input\nBijective: Both injective and surjective\n\nExample: \\(f(x) = 2x\\) on domain \\(\\mathbb{Z}\\) is injective but not surjective on \\(\\mathbb{Z}\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#odds",
    "href": "mathnotation.html#odds",
    "title": "Math Notation and Probability in R",
    "section": "Odds",
    "text": "Odds",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  },
  {
    "objectID": "mathnotation.html#implement-probability-calculations",
    "href": "mathnotation.html#implement-probability-calculations",
    "title": "Math Notation and Probability in R",
    "section": "Implement probability calculations",
    "text": "Implement probability calculations\n\n## Distance to substance abuse facility with medication-assisted treatment\ndist.mat &lt;- read.csv(\"data/opioidFacility.csv\")\n# Review the data\nsummary(dist.mat)\n\n    STATEFP         COUNTYFP          YEAR       INDICATOR        \n Min.   : 1.00   Min.   :  1.0   Min.   :2017   Length:3214       \n 1st Qu.:19.00   1st Qu.: 35.0   1st Qu.:2017   Class :character  \n Median :30.00   Median : 79.0   Median :2017   Mode  :character  \n Mean   :31.25   Mean   :101.9   Mean   :2017                     \n 3rd Qu.:46.00   3rd Qu.:133.0   3rd Qu.:2017                     \n Max.   :72.00   Max.   :840.0   Max.   :2017                     \n     VALUE           STATE           STATEABBREVIATION     COUNTY         \n Min.   :  0.00   Length:3214        Length:3214        Length:3214       \n 1st Qu.:  9.25   Class :character   Class :character   Class :character  \n Median : 18.17   Mode  :character   Mode  :character   Mode  :character  \n Mean   : 24.04                                                           \n 3rd Qu.: 31.00                                                           \n Max.   :414.86                                                           \n\nlibrary(tidyverse)\n# Graph the distance variable which is called Value but represents miles. \n# Note that this graph does not look normal - instead, it looks right or positive skewed. \nggplot(dist.mat, aes(VALUE)) + geom_histogram(fill = \"#7463AC\", color = \"white\") +labs(x = \"Miles to nearest substance abuse facility\", y = \"Number of counties\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\ndist.mat.cleaned &lt;- dist.mat %&gt;%\n     mutate(miles.cube.root = VALUE^(1/3)) %&gt;%\n     mutate(miles.log = log(x = VALUE)) %&gt;%\n     mutate(miles.inverse = 1/VALUE) %&gt;%\n     mutate(miles.sqrt = sqrt(x = VALUE))\n\nqnorm(.25, 10, 2)\n\n[1] 8.65102\n\nqnorm(0.95, mean = 500, sd = 10, lower.tail=FALSE)\n\n[1] 483.5515\n\npnorm(6, 7.5, .7)\n\n[1] 0.01606229\n\noptions(scipen=999)\npnorm(35, mean = 30, sd = 3/sqrt(5), lower.tail = FALSE)\n\n[1] 0.00009697081\n\ncuberoot &lt;-  ggplot(dist.mat.cleaned, aes(miles.cube.root)) +\n     geom_histogram(fill = \"#7463AC\", color = \"white\") + labs(x = \"Cube root\", y = \"Number of counties\"); cuberoot\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nlogged &lt;- ggplot(dist.mat.cleaned, aes(miles.log)) +\n     geom_histogram(fill = \"#7463AC\", color = \"white\") + labs(x = \"Log\", y = \"Number of counties\"); logged\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 20 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\ninversed &lt;- ggplot(dist.mat.cleaned, aes(miles.inverse)) +\n     geom_histogram(fill = \"#7463AC\", color = \"white\") + labs(x = \"Inverse\", y = \"Number of counties\")+ xlim(0, 1); logged\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 20 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nsquareroot &lt;- ggplot(dist.mat.cleaned, aes(miles.sqrt)) +\n     geom_histogram(fill = \"#7463AC\", color = \"white\") + labs(x = \"SQRT\", y = \"Number of counties\"); squareroot\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n# install.packages(\"gridExtra\")\ngridExtra::grid.arrange(cuberoot, logged, inversed, squareroot)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 20 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 34 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\ndist.mat.cleaned %&gt;%\n     drop_na(miles.cube.root) %&gt;%\n     summarize(mean.tran.dist = mean(x = miles.cube.root),sd.tran.dist = sd(x = miles.cube.root))\n\n  mean.tran.dist sd.tran.dist\n1       2.662915    0.7923114\n\n# P(X &lt; 3)\npnorm(3, 2.66, .79)\n\n[1] 0.6665403\n\n# P(X &gt; 3)\npnorm(3, 2.66, .79, lower.tail = FALSE)\n\n[1] 0.3334597\n\n# P(X &lt; 2)\npnorm(2, 2.66, .79)\n\n[1] 0.2017342\n\n#* We can use the equation to calculate the z-score for a county where you have to drive 15 miles to a facility. \n(15^(1/3) - 2.66)/0.79\n\n[1] -0.2453012\n\n# Next, we can calculate z for a county with residents who have to travel 50 miles to the nearest facility. In the transformed miles variable, this would be the cube root of 50, or a value of 3.68. \n(50^(1/3)-2.66)/0.79\n\n[1] 1.296242\n\n# A clinical trial shows that 10% of patients develop mild side effects from a new medication.\n# What is the probability of developing side effects?\n#     + What are the odds in favor of developing side effects?\n#    + What are the odds against developing side effects?\n\n# Given\np_side_effect &lt;- 0.1\n\n# Odds in favor\nodds_side_effect &lt;- p_side_effect / (1 - p_side_effect)\nodds_side_effect\n\n[1] 0.1111111\n\n# Odds against\nodds_against &lt;- (1 - p_side_effect) / p_side_effect\nodds_against\n\n[1] 9\n\n##Interpretation: Side effects are unlikely.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Math Notation and Probability in R</span>"
    ]
  }
]